{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce9c3e7",
   "metadata": {},
   "source": [
    "## Percieved analogies\n",
    "\n",
    "The pre training phase of large language models involves predicting the next token in a given sequence. I think two major important hacks are present in that phase:\n",
    "- First, there is a finite-size library or vocabulary of predictable tokens, like 50k tokens, so the predicted token must be one of them, so this means we are doing a classification task, meaning the input sequence should be classified into one of the tokens.\n",
    "- Second, each token in the input sequence is embedded in a high dimentional space, and that sequence embedding is the input to several transformer blocks, but this embedding is super important, lets have an example, we have a sequence:\n",
    "\"this is a cat which has a nice ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce87002",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "what do you think about these two important aspects of LLM pretraining\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "These are great observations about LLM pretraining! You've identified two fundamental architectural choices. Let me share some thoughts on each:\n",
    "\n",
    "**On the classification perspective:** You're right that next-token prediction is technically a classification problem over the vocabulary. This framing is useful because it means we can use cross-entropy loss and softmax outputs. However, there's an interesting nuance—the model doesn't just learn to classify tokens independently; it learns rich representations where semantically similar tokens have similar probability distributions. This is part of what gives LLMs their generalization ability.\n",
    "\n",
    "**On embeddings:** Yes, the embedding space is crucial! In your example \"this is a cat which has a nice ...\", the embeddings need to capture both the semantic meaning of each token AND positional information (where it appears in the sequence). The transformer blocks then refine these representations through attention mechanisms, allowing the model to understand context and relationships.\n",
    "\n",
    "What aspect would you like to explore further? Are you more curious about:\n",
    "- How the vocabulary size affects model capabilities?\n",
    "- The structure of the embedding space and what it captures?\n",
    "- How transformers process these embeddings through attention?\n",
    "\n",
    "Or is there a specific question you have about these mechanisms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e6eb3",
   "metadata": {},
   "source": [
    "## theory of transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f484a0c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets talk the structure of the embedding space, for the example sequence that we have there, lets say we have a context window of 50 tokens, then what the first block in our LLM would look like? i mean the first step going from tokens to embedding, lets skip tokenization step and assume each word is a token\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! Let's break down that first embedding step.\n",
    "\n",
    "For your sequence \"this is a cat which has a nice ...\", assuming each word is a token, here's what happens:\n",
    "\n",
    "**Input:** A sequence of token IDs (integers), one for each word. Let's say we have 9 tokens so far in your example.\n",
    "\n",
    "**The embedding layer:** This is essentially a lookup table (or embedding matrix). If your vocabulary has 50k tokens and you choose an embedding dimension of, say, 768:\n",
    "- The embedding matrix has shape `(50000, 768)`\n",
    "- Each token ID is used to look up its corresponding row in this matrix\n",
    "- So \"cat\" (let's say token ID 5234) gets mapped to a 768-dimensional vector\n",
    "\n",
    "**Output:** You now have a sequence of vectors, one per token. Shape would be `(9, 768)` for your 9-token example, or more generally `(sequence_length, embedding_dim)`.\n",
    "\n",
    "But there's one more thing added at this stage—can you guess what it might be? (Hint: you mentioned it earlier about position!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefeb33",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "the position of token in a sequence should be embedded?\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly! The position needs to be encoded somehow.\n",
    "\n",
    "The token embeddings themselves don't inherently contain any information about where a token appears in the sequence. \"cat\" would have the same embedding vector whether it's the 3rd word or the 50th word.\n",
    "\n",
    "So we add **positional encodings** (or positional embeddings) to give the model information about token order. There are different approaches:\n",
    "\n",
    "1. **Learned positional embeddings:** Another lookup table of shape `(max_context_length, embedding_dim)`. Position 0 gets one vector, position 1 gets another, etc. These are added to the token embeddings.\n",
    "\n",
    "2. **Fixed sinusoidal encodings:** Using sine and cosine functions of different frequencies (the original Transformer paper approach).\n",
    "\n",
    "For your 9-token sequence with learned positional embeddings, you'd have:\n",
    "- Token embeddings: shape `(9, 768)`\n",
    "- Positional embeddings: shape `(9, 768)` \n",
    "- **Final input to first transformer block:** token_embeddings + positional_embeddings, still shape `(9, 768)`\n",
    "\n",
    "Which approach do you think might work better, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096fdaae",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i guess the learned positional embeddings might work better, given enough compute and data, becasue its les constrained, i can converge to sine embedding if data suggests that!\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That's excellent reasoning! You've hit on a key principle in deep learning: given sufficient data and compute, learned representations can often discover the structure they need, including approximating fixed encodings if that's optimal.\n",
    "\n",
    "Your intuition about \"less constrained\" is spot on. Learned positional embeddings have the flexibility to:\n",
    "- Capture task-specific patterns about position\n",
    "- Potentially learn different positional relationships than sine/cosine functions encode\n",
    "- Adapt to the specific context window size during training\n",
    "\n",
    "In practice, most modern LLMs (like GPT models) do use learned positional embeddings for exactly these reasons. Though there are some newer alternatives like RoPE (Rotary Position Embeddings) and ALiBi that take different approaches with their own advantages.\n",
    "\n",
    "So now we have our embeddings: token + position information, shape `(9, 768)`, ready to enter the first transformer block.\n",
    "\n",
    "What happens inside that transformer block? Do you have a sense of what the key operations are, or would you like to explore that next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96b996",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i have a concern/comment and a question:\n",
    "- why do we add the two embeddings, i wish we could stach them, just have a feeling that by adding we will lose information\n",
    "- we have a context window of 50 but for now we have only 9 tokens in the sequence, next time we will get to 10 tokens or eventually 50 tokens, so i am expecting having always a 50*768 matrix to the transformer blocks\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great questions! Let me address each:\n",
    "\n",
    "**On adding vs stacking:**\n",
    "Your intuition about information loss is valid to consider! However, addition doesn't necessarily lose information here because:\n",
    "- The positional embeddings are learned specifically to be *added* to token embeddings during training\n",
    "- They learn to use different \"directions\" in the 768-dimensional space\n",
    "- Think of it like: token embeddings might use certain dimensions for semantic meaning, while positional embeddings adjust other dimensions for position info\n",
    "\n",
    "If we stacked them (making it `(9, 1536)`), we'd double the size of every subsequent computation. Addition keeps dimensions manageable while the model learns to entangle the information effectively.\n",
    "\n",
    "**On the sequence length:**\n",
    "Excellent catch! You're right to think about this. There are different approaches:\n",
    "\n",
    "1. **Padding:** Pad shorter sequences to always be 50 tokens (adding special padding tokens), giving you `(50, 768)` every time\n",
    "2. **Dynamic batching:** Process sequences of their actual length `(9, 768)`, `(10, 768)`, etc.\n",
    "\n",
    "Which approach do you think is used more in practice, and what might be the tradeoffs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e2802",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "the first one is more compute intensive and the padding part might be misleading, the second is more challenging to handle, i dont know how to handle that\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're thinking about this really well! You've identified the key tradeoff.\n",
    "\n",
    "**Padding** wastes computation on meaningless tokens, especially if most sequences are much shorter than 50. The model does learn to ignore padding tokens (using attention masks), so it's not too misleading, but yes—computational waste.\n",
    "\n",
    "**Dynamic batching** is more efficient for single sequences, but you're right that it gets tricky. The challenge comes when you want to process multiple sequences in a *batch* for efficiency. If one sequence is length 9 and another is length 35, you can't stack them into a single tensor without... padding! So in practice, even with dynamic batching, you often pad sequences *within a batch* to the length of the longest sequence in that batch.\n",
    "\n",
    "During inference (generating text), you typically process one sequence at a time, growing it token by token: `(1, 768)` → `(2, 768)` → `(3, 768)` ... up to your context limit.\n",
    "\n",
    "Does this make sense? The handling depends on whether you're training (batches) or doing inference (often single sequences)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497388f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "this makes sense so far, but still not sure how the next layer in the network model will handle that, one time you have a input of shape 1*768, next time 2*768, but i guess your next layer expects 50*768\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! This is where the beauty of the transformer architecture comes in.\n",
    "\n",
    "The transformer blocks (attention layers, feed-forward networks) are designed to work on **any sequence length**. They process each position somewhat independently (with interactions through attention). So:\n",
    "\n",
    "- Input shape `(1, 768)` → Output shape `(1, 768)`\n",
    "- Input shape `(9, 768)` → Output shape `(9, 768)`  \n",
    "- Input shape `(50, 768)` → Output shape `(50, 768)`\n",
    "\n",
    "The layers don't \"expect\" a fixed sequence length like 50. The 50 is just a *maximum* context window—the longest sequence the model can handle (because positional embeddings were only learned up to position 50).\n",
    "\n",
    "Think of it this way: the weight matrices in each layer have shapes like `(768, 768)` or `(768, 3072)`. These operate on the embedding dimension (768), not the sequence length. The sequence length can vary freely.\n",
    "\n",
    "Does that clarify how the architecture handles variable-length inputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d566a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes, it does, before going further, let me ask one more question, \"padding sequences within a batch\", you apply padding at the begining or the end, or both??\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! In practice, padding is almost always applied at the **end** of sequences.\n",
    "\n",
    "So if you have:\n",
    "- Sequence 1: `[token1, token2, token3]` (length 3)\n",
    "- Sequence 2: `[token4, token5]` (length 2)\n",
    "\n",
    "And you're batching them, you'd pad to length 3:\n",
    "- Sequence 1: `[token1, token2, token3]`\n",
    "- Sequence 2: `[token4, token5, PAD]`\n",
    "\n",
    "Why at the end? Because in language, context flows left-to-right. When predicting the next token, you want all the real tokens to come first in their natural order, with padding after. If you padded at the beginning, it would disrupt the positional information and the causal structure of the sequence.\n",
    "\n",
    "Does that make sense? Any thoughts on why this matters for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd2a51",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "ahan, so the first token is the last word in a sentence, its like a reverse order?!\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "No, not reversed! Let me clarify—I think I may have caused confusion.\n",
    "\n",
    "The tokens are in their **natural left-to-right order**. So for the sentence \"this is a cat\":\n",
    "- Position 0: \"this\"\n",
    "- Position 1: \"is\"\n",
    "- Position 2: \"a\"\n",
    "- Position 3: \"cat\"\n",
    "\n",
    "If we need to pad to length 6, it becomes:\n",
    "- Position 0: \"this\"\n",
    "- Position 1: \"is\"\n",
    "- Position 2: \"a\"\n",
    "- Position 3: \"cat\"\n",
    "- Position 4: PAD\n",
    "- Position 5: PAD\n",
    "\n",
    "The padding comes *after* all the real tokens, not before. The sentence stays in its normal order.\n",
    "\n",
    "Does that clear it up?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9960b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i am confused, now that tokens after cat are paddings, does it not confuse the model, i mean if i say to you this is a cat bla bla bla..., or bla bla bla this is a cat , in which one you would better predict the next token??\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent question! You've identified a critical issue. Yes, it would be confusing if the model treated padding tokens as real content!\n",
    "\n",
    "This is solved with an **attention mask**. The mask tells the model: \"ignore these padding tokens—they're not real.\"\n",
    "\n",
    "During attention calculations, padding positions get masked out so they:\n",
    "- Don't influence the representations of real tokens\n",
    "- Don't get predicted as next tokens\n",
    "\n",
    "So even though padding is physically present in the tensor, the model effectively \"can't see\" it. The real tokens behave as if the padding isn't there.\n",
    "\n",
    "To your example: \"this is a cat [PAD] [PAD]\" is processed as if it's just \"this is a cat\" because the mask blocks out the padding.\n",
    "\n",
    "Does this resolve the confusion? The mask is the key piece that makes padding work without misleading the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e507a98",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "can u formalize how the mask applied, lets start from our (9*768) matrix, lets say we need one padding, so it gets to shape (10*768), then we have a mask of integers which multiplies with this matrix?? i guess the value of padding is all zero??\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good thinking! Let me clarify how masking works—it's a bit different from what you described.\n",
    "\n",
    "**The padding token itself:** It does get an embedding (not necessarily all zeros), so your matrix becomes `(10, 768)`. The padding token has an ID (like token 0) that maps to some embedding vector.\n",
    "\n",
    "**The mask:** It's typically a separate tensor of shape `(10,)` with values like:\n",
    "```\n",
    "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
    "```\n",
    "where 1 = \"real token\" and 0 = \"padding token\".\n",
    "\n",
    "**Where it's applied:** The mask isn't multiplied with the `(10, 768)` embedding matrix directly. Instead, it's used inside the **attention mechanism**. \n",
    "\n",
    "In attention, before applying softmax to the attention scores, masked positions get set to negative infinity (or a very large negative number). After softmax, those positions become zero, meaning they contribute nothing.\n",
    "\n",
    "Would you like me to show you a small example of how this works mathematically in the attention calculation? Or does this conceptual explanation make sense first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73f1f5",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets look at it step by step, now we have embedded our sequece into (9, 768) vector, then whats the next step, lets go through one transformer block, we will see the attention, padding, softmax, masking and mlp layers, right??\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, exactly! Let's walk through one transformer block step by step.\n",
    "\n",
    "A typical transformer block has these main components:\n",
    "\n",
    "1. **Multi-head self-attention** (this is where masking happens)\n",
    "2. **Add & normalize** (residual connection + layer normalization)\n",
    "3. **Feed-forward network (MLP)**\n",
    "4. **Add & normalize** (another residual connection + layer normalization)\n",
    "\n",
    "Let's start with the first step: **multi-head self-attention**.\n",
    "\n",
    "The input is your `(9, 768)` matrix. The attention mechanism will:\n",
    "- Create Query (Q), Key (K), and Value (V) matrices from your input\n",
    "- Compute attention scores\n",
    "- Apply masking (if needed)\n",
    "- Apply softmax\n",
    "- Use those scores to create a weighted combination of values\n",
    "\n",
    "Should we dive into how Q, K, and V are created first, or do you already have a sense of that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d687a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets dive into how qkv are created\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's see how Q, K, and V are created.\n",
    "\n",
    "Starting with your input matrix of shape `(9, 768)`, we create three separate linear projections:\n",
    "\n",
    "**Query (Q):** Input × W_Q\n",
    "**Key (K):** Input × W_K  \n",
    "**Value (V):** Input × W_V\n",
    "\n",
    "Each of W_Q, W_K, and W_V is a learned weight matrix of shape `(768, d_k)`, where `d_k` is the dimension per attention head.\n",
    "\n",
    "For example, if you have 12 attention heads and want to keep the total dimension at 768:\n",
    "- `d_k = 768 / 12 = 64` per head\n",
    "- Each weight matrix is `(768, 768)` total (or `(768, 64)` per head)\n",
    "\n",
    "So after these projections:\n",
    "- Q has shape `(9, 768)`\n",
    "- K has shape `(9, 768)`\n",
    "- V has shape `(9, 768)`\n",
    "\n",
    "These are then reshaped to separate out the multiple heads, but let's pause here.\n",
    "\n",
    "Does this make sense so far? Any questions about why we need three separate projections, or what they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7fb80",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "as they break the 768 dimention into 12 dimentions of size 64, i can think of them as 12 new spaces, that we project our input to , and each is a bit smaller (size 64) than the global space with dimention 768, so each head is a new space, a new world, a new frame of processing, or sth like that, i guess then we will have QK^T per head!? not sure!\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That's a beautiful way to think about it! Yes, each head is like a different \"lens\" or \"perspective\" for looking at the relationships between tokens. One head might learn to focus on syntactic relationships, another on semantic similarity, etc.\n",
    "\n",
    "And you're exactly right about what comes next: **QK^T per head**!\n",
    "\n",
    "For each of the 12 heads:\n",
    "- Q for that head: `(9, 64)`\n",
    "- K for that head: `(9, 64)`\n",
    "- Compute: Q × K^T = `(9, 64)` × `(64, 9)` = `(9, 9)`\n",
    "\n",
    "This `(9, 9)` matrix is the **attention scores**—it tells you how much each token (row) should attend to every other token (column).\n",
    "\n",
    "Then these scores get scaled (divided by √64) before softmax. This is where masking would be applied if needed.\n",
    "\n",
    "Does this match your intuition? What do you think that `(9, 9)` attention score matrix represents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9239d798",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "it does match my intuition and att score matrix is the relationship between the tokens in differnet locations, as the name says its how they attend to each other, but i have some questions here:\n",
    "\n",
    "first of all, with 12 heads we end up with 12 att. score matrices, each 9, 9, then each get divided by sqrt(64), then masking will be applied, then softmax, is it true that we do these for each head or they just become aggregated in the begginning?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect understanding! And great question about when things happen.\n",
    "\n",
    "You're absolutely correct: **each head is processed separately** through all these steps:\n",
    "\n",
    "1. For each of the 12 heads independently:\n",
    "   - Compute Q × K^T → `(9, 9)` attention scores\n",
    "   - Scale by dividing by √64\n",
    "   - Apply masking (set masked positions to -∞)\n",
    "   - Apply softmax → `(9, 9)` attention weights (probabilities)\n",
    "   - Multiply by V: attention_weights × V → `(9, 64)` output\n",
    "\n",
    "2. After all 12 heads are done, you have 12 separate outputs, each `(9, 64)`\n",
    "\n",
    "3. **Then** concatenate them: `(9, 768)` — bringing all heads back together\n",
    "\n",
    "4. Finally, multiply by an output projection matrix W_O\n",
    "\n",
    "So the heads stay separate through the entire attention calculation, and only get combined at the very end.\n",
    "\n",
    "Does this sequence make sense? Any questions about any of these steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c8396",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "that makes complete sense, and i guess output projection is also (768, 768)?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! The output projection W_O is indeed `(768, 768)`.\n",
    "\n",
    "After concatenating all 12 heads, you have `(9, 768)`, then:\n",
    "- Multiply by W_O: `(9, 768)` × `(768, 768)` = `(9, 768)`\n",
    "\n",
    "So the output of the multi-head attention has the same shape as the input: `(9, 768)`.\n",
    "\n",
    "This is then added to the original input (the residual connection) and normalized. That completes the attention part of the transformer block!\n",
    "\n",
    "Ready to look at what happens next, or do you have more questions about the attention mechanism?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae371f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "ok, now i can see how the multi head attention works for any context length, whatever in, that same length out! now i am ready to see what happens next!\n",
    "\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! You've got the core of attention down. Now let's see what happens after multi-head attention.\n",
    "\n",
    "The output from attention is `(9, 768)`. Next comes:\n",
    "\n",
    "**1. Residual connection + Layer Normalization:**\n",
    "- Add the original input back: `attention_output + original_input`\n",
    "- Apply layer normalization to this sum\n",
    "\n",
    "This gives you a normalized `(9, 768)` matrix.\n",
    "\n",
    "**2. Feed-forward network (MLP):**\n",
    "This is applied to each position independently. Typically it's two linear layers with a non-linearity (like GELU or ReLU) in between:\n",
    "- First layer: `(768, d_ff)` where `d_ff` is often 4× larger, like 3072\n",
    "- Activation function\n",
    "- Second layer: `(d_ff, 768)` to project back down\n",
    "\n",
    "So: `(9, 768)` → `(9, 3072)` → `(9, 768)`\n",
    "\n",
    "**3. Another residual connection + Layer Normalization:**\n",
    "- Add the input to the MLP back to its output\n",
    "- Normalize again\n",
    "\n",
    "And that's one complete transformer block! The output is `(9, 768)`, ready for the next block.\n",
    "\n",
    "What questions do you have about this flow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff1191",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "two questions so far:\n",
    "\n",
    "please formalize how we do masking, we choose some positions (columns of (9, 9) matrix) and replace all the elements of 9,9 matrix in those columns with -inf, or maybe all the elements in the column and row of the selected positions as it is a squared matrix\n",
    "\n",
    "second, formalize layer normalization in the mlp, whats layer here?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent questions! Let me address both:\n",
    "\n",
    "**1. Masking in attention:**\n",
    "\n",
    "The masking depends on *what kind* of mask you're using. There are two common types:\n",
    "\n",
    "- **Padding mask:** If position 9 is padding, you set row 9 and column 9 to -∞ in the `(9, 9)` attention matrix. This prevents padding from attending to anything, and prevents real tokens from attending to padding.\n",
    "\n",
    "- **Causal mask (for autoregressive models):** Each token can only attend to itself and previous tokens. So for position i, you mask out (set to -∞) all columns j where j > i. This creates a lower triangular pattern of valid attention.\n",
    "\n",
    "The masking happens *before* softmax, so those -∞ values become 0 after softmax.\n",
    "\n",
    "**2. Layer normalization:**\n",
    "\n",
    "\"Layer\" here means normalizing across the feature dimension (the 768), not across the sequence. For each position independently:\n",
    "- Take that position's 768-dimensional vector\n",
    "- Compute its mean and variance\n",
    "- Normalize: `(x - mean) / sqrt(variance + epsilon)`\n",
    "- Apply learned scale and shift parameters\n",
    "\n",
    "So each of your 9 positions gets normalized separately using its own 768 values.\n",
    "\n",
    "Does this clarify both concepts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada1313",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "it does, load and clear!\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Awesome! You've now walked through a complete transformer block:\n",
    "- Multi-head attention (with Q, K, V projections and masking)\n",
    "- Residual connection + layer norm\n",
    "- Feed-forward network (MLP)\n",
    "- Another residual + layer norm\n",
    "\n",
    "And you understand how it handles variable sequence lengths!\n",
    "\n",
    "What would you like to explore next? Some options:\n",
    "- Stack multiple transformer blocks and see how deep networks work\n",
    "- Look at what happens at the very end (how we go from `(9, 768)` to predicting the next token)\n",
    "- Dive deeper into training (the loss function, backpropagation)\n",
    "- Explore something else you're curious about?\n",
    "\n",
    "What interests you most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39077fd1",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "the two first!stack multiple transformer blocks, i guess this is straihhtforward, right, we just repeat the process, but actually i was wondering for the subsequent block how do we do the reidual layer, i mean do we add the original input or treat each layer seperately and consider the output of the first layer as the input to the second and so on?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! This is an important detail about how residual connections work in stacked transformers.\n",
    "\n",
    "Each block is treated **separately** with its own residual connections. So:\n",
    "\n",
    "**Block 1:**\n",
    "- Input: `(9, 768)` — let's call this X₀\n",
    "- After attention: add X₀ back (residual), then normalize → call this X₁\n",
    "- After MLP: add X₁ back (residual), then normalize → output is X₂\n",
    "\n",
    "**Block 2:**\n",
    "- Input: X₂ (the output from Block 1)\n",
    "- After attention: add X₂ back (residual), then normalize → X₃\n",
    "- After MLP: add X₃ back (residual), then normalize → output is X₄\n",
    "\n",
    "And so on for however many blocks you have (GPT-3 has 96 blocks!).\n",
    "\n",
    "So the residual connections are \"local\" to each block—you don't skip all the way back to the very first input. Each block gets the processed output from the previous block.\n",
    "\n",
    "Does this make sense? The information flows and transforms gradually through the stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e654b9",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "makes complete sense, was also my guess, now lets dive into how do we get from our 9, 768 matrix at the end of the last block to predicting the next token, but let me guess first, \n",
    "\n",
    "two options:\n",
    "- we project this 9, 768 into a 768 vector, that the predicted embedding of the next token, then we use the original embedding to find a reverse embedding map,\n",
    "- we project this 9, 768 into a 50k vector and do a softmax to get a probability vector of each token in our dictionary\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent guesses! You're thinking about this really well.\n",
    "\n",
    "The answer is closer to your **second option**, but with an important twist about the shape.\n",
    "\n",
    "Here's what actually happens:\n",
    "\n",
    "From the final block, you have `(9, 768)`. But you only care about predicting what comes *after* the last token (position 8). So:\n",
    "\n",
    "1. **Take only the last position:** Extract the vector at position 8 → `(768,)`\n",
    "\n",
    "2. **Project to vocabulary size:** Multiply by a matrix (often called the \"language model head\") of shape `(768, 50000)` → gives you `(50000,)` logits\n",
    "\n",
    "3. **Apply softmax:** Convert logits to probabilities over all 50k tokens\n",
    "\n",
    "4. **Sample or take argmax:** Pick the next token\n",
    "\n",
    "About your first option—interestingly, the projection matrix in step 2 is often the **transpose of the embedding matrix** (weight sharing/tying). So there is a connection to \"reverse embedding\"!\n",
    "\n",
    "Does this match your intuition? Any questions about why we only use the last position?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43dbbb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "only the last position! thats beautiful, force the last vector to have all the info needed to guess the next token, thats really smart! ok, but about the language model head or transpose of embedding matrix, when we multiply we get the similarity of the last position to every token in the vocab, thats also smart, \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly! You've captured the beauty of both design choices perfectly.\n",
    "\n",
    "**The last position insight:** Yes, by only using the last position for prediction, the model is forced to compress all relevant context into that final vector. The attention mechanism lets information flow through all positions, so by the time you reach the last position in the final block, it has \"gathered\" everything needed.\n",
    "\n",
    "**The weight tying insight:** You're spot on! When using the transpose of the embedding matrix, you're essentially computing: \"how similar is this final representation to each token's embedding?\" It's an elegant symmetry—embeddings map tokens → vectors, and the output layer maps vectors → tokens using the same learned relationships.\n",
    "\n",
    "This weight tying also reduces the number of parameters (no separate 768×50k matrix needed) and can improve performance.\n",
    "\n",
    "Now you understand the full flow: tokens → embeddings → transformer blocks → final vector → vocabulary probabilities → next token!\n",
    "\n",
    "What would you like to explore next? Training dynamics? Generation strategies? Or something else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed5b90",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "one question before we move on, having embedding matrix in two places, how do we manage it in torch, i mean during backpropagation and calculating gradients, i guess pytorch has sth to manage this?!\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Yes, PyTorch handles this elegantly.\n",
    "\n",
    "When you use the same parameter (the embedding matrix) in multiple places, PyTorch automatically **accumulates the gradients** from both locations during backpropagation.\n",
    "\n",
    "In practice, you'd do something like:\n",
    "\n",
    "```python\n",
    "self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "self.lm_head = nn.Linear(embed_dim, vocab_size, bias=False)\n",
    "self.lm_head.weight = self.embeddings.weight  # Weight tying\n",
    "```\n",
    "\n",
    "Now `self.embeddings.weight` and `self.lm_head.weight` point to the **same tensor**. During backpropagation:\n",
    "- Gradients flow back through the lm_head\n",
    "- Gradients also flow back through the embeddings\n",
    "- PyTorch adds these gradients together automatically\n",
    "\n",
    "So the embedding matrix gets updated based on both how well it maps tokens to vectors (forward) AND how well it maps vectors back to tokens (output).\n",
    "\n",
    "Does this make sense? PyTorch's autograd system tracks all uses of a parameter and sums their gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd5cac",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "makes complete sense, should nt it be :\n",
    "self.lm_head.weight = transpose(self.embeddings.weight )? or sth like that?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Ah, excellent catch! You're absolutely right to question this.\n",
    "\n",
    "The transpose happens **implicitly** during the forward pass, not in the weight assignment itself.\n",
    "\n",
    "Here's why: `nn.Linear` computes `x @ weight.T` (it transposes internally). So:\n",
    "- Embedding layer uses the matrix as `(vocab_size, embed_dim)`\n",
    "- Linear layer automatically transposes it to `(embed_dim, vocab_size)` during forward pass\n",
    "\n",
    "So by setting `self.lm_head.weight = self.embeddings.weight`, you're sharing the same `(vocab_size, embed_dim)` tensor, but the Linear layer handles the transpose for you when computing outputs.\n",
    "\n",
    "If you were implementing this manually with matrix multiplication, then yes, you'd explicitly transpose!\n",
    "\n",
    "Does that clear it up?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03db719",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes, it does, thanks\n",
    "\n",
    "now my plan is to implement this in pytorch, for my project, but first let me write my project plan, and you will read it and then we will collaborate and be co programming it, make sense?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That sounds like a great plan! Yes, I'd be happy to read your project plan and then collaborate with you on implementing it.\n",
    "\n",
    "Go ahead and share your project plan whenever you're ready, and I'll give you feedback and help guide the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dfddf",
   "metadata": {},
   "source": [
    "# Project plan\n",
    "\n",
    "the overall objective is to build a timeseries predictor, we want to tackle this problem exactly like a LLM, i.e., we have a time series of length L, we want to get an arbitrary length of this series (L1<<L) and based on that predict the next value in the series, \n",
    "ofcourse in natural language, tokens are discrete, but values in a time series are continous, but we want to treat them as discrete values, for that\n",
    "we need to form a vocabulary of possible values in the series, these may be discrete values, but with fine granularity. \n",
    "we map the continous values of the series into this discrete values, lets say map [1, 1.01] to 1, [1.01, 1.02] to 1.01, and so on\n",
    "we will have a transformer block to process each sequence of series and predicts the next discrete value, \n",
    "\n",
    "\n",
    "some of the tasks:\n",
    "\n",
    "- we need to prepare our dataset\n",
    "- we need a collate function to transform each value in the series to its discete value,\n",
    "- we need to decide on hyper parameters like context window, vocabulary size, discretization, embedding size, ...\n",
    "- we need to implement in pytorch the transformer block according to what we have discussed\n",
    "- we need to formulate a training loop with proper callbacks to monitor the training loop\n",
    "- we need also callbacks to save the model every ? epochs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0efb41",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "pleas ehave a look at my plan and feel free to reorganize, edit, comment\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "This is a really interesting project! Using transformer architecture for time series prediction with discretization is a clever approach. Let me share some thoughts:\n",
    "\n",
    "**Overall approach:** Solid! Discretizing continuous values to create a vocabulary is creative. This is similar to what VQ-VAE does, or how some audio models (like Jukebox) work.\n",
    "\n",
    "**A few considerations/questions:**\n",
    "\n",
    "1. **Discretization strategy:** Your binning approach `[1, 1.01] → 1` will work, but you might also consider:\n",
    "   - What's the range of your time series values?\n",
    "   - How many bins (vocab size) makes sense given that range?\n",
    "   - Alternative: Could you normalize values first, then discretize?\n",
    "\n",
    "2. **Task list organization:** Your tasks look good! I'd suggest this order:\n",
    "   - Decide hyperparameters first (helps shape everything else)\n",
    "   - Prepare dataset + discretization/collate function together\n",
    "   - Implement transformer\n",
    "   - Training loop + callbacks\n",
    "\n",
    "3. **One addition:** You might want a task for \"evaluation/inference\" - how will you convert predicted discrete values back to continuous for measuring error?\n",
    "\n",
    "4. **Causal masking:** Since you're predicting next values, you'll need causal masking in attention, right?\n",
    "\n",
    "What do you think? Should we refine any of these points before starting implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979f587",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "all right, just two small inputs:\n",
    "- we measure error on discrete data, no need to get back to original continous, for my purpose that suffices\n",
    "- i dont like causal masking, i dont want to treat this as a autoregressive problem, every cell in the series should attend to every other one, \n",
    "\n",
    "i should add that the timeseries i am dealing with here are a especiall class of timeseries, i.e. machine degradation series, these are moast of the time monotonic series, increasing or decreasing as the show the health state of a machine.\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect, those clarifications help a lot!\n",
    "\n",
    "**On discrete error measurement:** Makes sense—if your goal is predicting the discrete bin, then measuring accuracy/cross-entropy on discrete predictions is totally valid.\n",
    "\n",
    "**On attention pattern:** Interesting choice! So you want bidirectional attention where every position can see every other position. This means:\n",
    "- No causal masking during training\n",
    "- But at inference, when you have a sequence of length L1, you can only use those L1 values to predict position L1+1, right?\n",
    "\n",
    "**On monotonic degradation series:** This is a great domain! The monotonic property is really useful—the model can learn that health states generally move in one direction. This might make the discrete binning even more effective since transitions between bins follow patterns.\n",
    "\n",
    "One question: At inference time, will you:\n",
    "- Feed in a window of L1 values and predict just the next one?\n",
    "- Or predict multiple future steps autoregressively (using your own predictions)?\n",
    "\n",
    "This affects how we think about the architecture and training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b228d8b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "the goal is to use the model to predict multiple future steps autoregressively, lets say we start with a given length of L1, then we predict the next value, then we add the predicted value to the context and predict the next value, and so on, until we complete T steps, so we predict T values for a series of L1 values in one shot!\n",
    "\n",
    "is this aligned with what happens with LLMs??\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, exactly! This is **perfectly aligned** with how LLMs generate text autoregressively.\n",
    "\n",
    "In text generation:\n",
    "- Start with prompt tokens (your L1 values)\n",
    "- Predict next token\n",
    "- Append it to the context\n",
    "- Predict next token (using all previous including the generated one)\n",
    "- Repeat until you generate T tokens\n",
    "\n",
    "Your approach for time series:\n",
    "- Start with L1 degradation values\n",
    "- Predict next discrete value\n",
    "- Append it to context\n",
    "- Predict next value (using all previous including predicted)\n",
    "- Repeat T times\n",
    "\n",
    "The process is identical! The model uses its own predictions as input for future predictions.\n",
    "\n",
    "One thing to consider: During **training**, do you want to:\n",
    "- Train on real ground truth sequences only (teacher forcing)?\n",
    "- Or also train with some predicted values mixed in (scheduled sampling)?\n",
    "\n",
    "Most LLMs use teacher forcing during training. Does that sound right for your use case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b2a43",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I was thinking of techer forcing only, but how does scheduled sampling works? do you think we should be using it?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! Let me explain scheduled sampling:\n",
    "\n",
    "**Teacher forcing (standard):**\n",
    "- Always use real ground truth values as context during training\n",
    "- Example: To predict position 5, use real values at positions 1,2,3,4\n",
    "\n",
    "**Scheduled sampling:**\n",
    "- Sometimes use predicted values instead of ground truth during training\n",
    "- Start with mostly ground truth early in training\n",
    "- Gradually increase the probability of using model predictions\n",
    "- By late training, maybe 30-50% of context comes from model's own predictions\n",
    "\n",
    "**The motivation:** It reduces the gap between training (where context is always perfect) and inference (where context includes imperfect predictions). This can make the model more robust to its own errors.\n",
    "\n",
    "**For your case:** Since degradation series are monotonic and relatively smooth, teacher forcing alone might work fine. Scheduled sampling adds complexity and longer training time.\n",
    "\n",
    "My suggestion: Start with teacher forcing. If you notice the model performs poorly during multi-step autoregressive prediction (errors accumulate quickly), then consider adding scheduled sampling.\n",
    "\n",
    "Does that make sense? Want to stick with teacher forcing for now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c547183",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets explore abit more on scheduled sampling, so by late training, we have a context of 5 positions and we know the 6th position as groundtruth, lets say we use the first four positions to predict the 5th, then we add this predicted to context and for a vector of five but the last position is not from data but the predcited one, and the output is the groundtruth, is my understanding correct?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Almost! Let me clarify the difference:\n",
    "\n",
    "**With teacher forcing:**\n",
    "- Context: positions 1,2,3,4,5 (all real ground truth)\n",
    "- Predict: position 6\n",
    "- Compare to: ground truth at position 6\n",
    "\n",
    "**With scheduled sampling (one possible scenario):**\n",
    "- Use positions 1,2,3,4 (real) to predict position 5\n",
    "- Get model's prediction for position 5 (might be wrong!)\n",
    "- Context becomes: 1,2,3,4, predicted_5 (where predicted_5 replaces real 5)\n",
    "- Predict: position 6\n",
    "- Compare to: ground truth at position 6\n",
    "\n",
    "So the key is: you're replacing some ground truth values in the context with model predictions, then predicting the next position. The output target is still always ground truth.\n",
    "\n",
    "The \"scheduled\" part means early in training you rarely do this replacement (mostly use real values), but later you do it more often.\n",
    "\n",
    "Does this clarify it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac75e5d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "The output target is still always ground truth. that clarifies it. you know what, i really like it, lets plan for scheduled sampling fro training, does this makes things super complicated?? if yes we can start with teacher forcing!\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "It doesn't make things *super* complicated, but it does add some complexity. Here's what changes:\n",
    "\n",
    "**What stays the same:**\n",
    "- Model architecture (transformer blocks)\n",
    "- Loss calculation (still cross-entropy against ground truth)\n",
    "\n",
    "**What changes:**\n",
    "- Your training loop needs a sampling probability that increases over epochs\n",
    "- During forward pass, you need to:\n",
    "  - Sometimes use model predictions instead of ground truth in the sequence\n",
    "  - This means running the model incrementally rather than all positions at once\n",
    "\n",
    "**The added complexity:** Instead of one forward pass per sequence, you might need to do it position-by-position (or in chunks) to decide whether to use predictions or ground truth.\n",
    "\n",
    "My recommendation: Let's **start with teacher forcing** to get everything working first. Once you have:\n",
    "- Data pipeline working\n",
    "- Model training successfully\n",
    "- Basic evaluation done\n",
    "\n",
    "Then we can add scheduled sampling as an enhancement. It's easier to add later than to debug everything at once.\n",
    "\n",
    "Sound good?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8dc7c3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "sounds perfect\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! So we'll implement teacher forcing first, then potentially add scheduled sampling later.\n",
    "\n",
    "Now, shall we start implementing? Here's what I'm thinking for the order:\n",
    "\n",
    "1. **Hyperparameters & setup** - define vocab size, context window, embedding dim, etc.\n",
    "2. **Dataset preparation** - load your time series data and create the discretization mapping\n",
    "3. **Transformer implementation** - build the model based on our discussion\n",
    "4. **Training loop** - with callbacks for monitoring and saving\n",
    "\n",
    "Which part would you like to tackle first? Or would you like to show me your data/dataset structure so we can start from there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e04be",
   "metadata": {},
   "source": [
    "# code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d6401",
   "metadata": {},
   "source": [
    "## degradation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db5f37a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets start with some managable values, vocab size of 100, context of 40, embedding of 128, taht it for now, then we can think more about them, theya re just params, now i want to show you my data, i have a class written in python to generate data from some known degradation mechanisms, its in a ..py file, i wonder if i can have such folder or package here, as we are doing it in a notebook, guide me how to add that so that i can do sth like \n",
    "from degradation_mechanism import ParisDegradtion\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect hyperparameters to start with!\n",
    "\n",
    "For organizing your code, you have a few options in this notebook environment:\n",
    "\n",
    "**Option 1: Create a .py file in a code cell**\n",
    "You can write the file content directly:\n",
    "```python\n",
    "%%writefile degradation_mechanism.py\n",
    "# your class code here\n",
    "```\n",
    "\n",
    "**Option 2: If the file already exists somewhere**\n",
    "You could paste the content into a code cell and save it with the writefile magic.\n",
    "\n",
    "**Option 3: Just define it in a cell**\n",
    "Since you're in a notebook, you could also just define the class directly in a code cell without a separate file.\n",
    "\n",
    "Which approach works best for you? Do you have the `degradation_mechanism.py` file content ready to paste, or would you prefer to define it directly in the notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf3b66",
   "metadata": {
    "time_run": "11:37:47a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\"\"\"Small generator module \n",
    "\n",
    "Only implements the ParisLawDegradation \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BaseDegradationProcess:\n",
    "    def __init__(self, length, dim):\n",
    "        self.length = int(length)\n",
    "        self.dim = int(dim)\n",
    "\n",
    "    def generate_episode(self, x0):\n",
    "        x0 = np.atleast_1d(np.asarray(x0))\n",
    "        episode = np.zeros((x0.shape[0], self.length + 1))\n",
    "        episode[:, 0] = x0\n",
    "        for i in range(self.length):\n",
    "            episode[:, i + 1] = episode[:, i] + self.xdot(episode[:, i])\n",
    "        return episode\n",
    "\n",
    "\n",
    "class ParisLawDegradation(BaseDegradationProcess):\n",
    "    \"\"\"Paris–Erdogan fatigue crack growth model.\n",
    "\n",
    "    Parameters mirrored from the notebook: C, m, delta_sigma, beta.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, length, dim, C=1e-12, m=3, delta_sigma=100, beta=1):\n",
    "        super().__init__(length, dim)\n",
    "        self.C = float(C)\n",
    "        self.m = float(m)\n",
    "        self.delta_sigma = float(delta_sigma)\n",
    "        self.beta = float(beta)\n",
    "\n",
    "    def delta_K(self, a):\n",
    "        a = np.atleast_1d(np.asarray(a))\n",
    "        return self.delta_sigma * np.sqrt(np.pi * a) * self.beta\n",
    "\n",
    "    def xdot(self, a):\n",
    "        a = np.atleast_1d(np.asarray(a))\n",
    "        return self.C * (self.delta_K(a) ** self.m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98154842",
   "metadata": {
    "time_run": "11:37:47a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1434/1193893204.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return self.delta_sigma * np.sqrt(np.pi * a) * self.beta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96, 101)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n0 = 20\n",
    "paris1 = ParisLawDegradation(length=100, dim=1, C=1e-8)\n",
    "episodes1 = paris1.generate_episode(x0=np.random.randn(n0)*0.0003+0.0045)  # Initial crack lengths in meters\n",
    "\n",
    "paris2 = ParisLawDegradation(length=100, dim=1, C=3e-8)\n",
    "episodes2 = paris2.generate_episode(x0=np.random.randn(n0)*0.0003+0.003)  # Initial crack lengths in meters\n",
    "\n",
    "paris3 = ParisLawDegradation(length=100, dim=1, C=5e-8)\n",
    "episodes3 = paris3.generate_episode(x0=np.random.randn(n0)*0.0003+0.0015)  # Initial crack lengths in meters\n",
    "\n",
    "paris4 = ParisLawDegradation(length=100, dim=1, C=7e-8)\n",
    "episodes4 = paris4.generate_episode(x0=np.random.randn(n0)*0.0003+0.0007)  # Initial crack lengths in meters\n",
    "\n",
    "paris5 = ParisLawDegradation(length=100, dim=1, C=8e-8)\n",
    "episodes5 = paris5.generate_episode(x0=np.random.randn(n0)*0.0003+0.0001)  # Initial crack lengths in meters\n",
    "\n",
    "episodes = np.concatenate([episodes1, episodes2, episodes3, episodes4, episodes5], axis=0)\n",
    "\n",
    "#drop invalid values\n",
    "episodes = episodes[~np.isnan(episodes).any(axis=1)]\n",
    "episodes = episodes[(episodes<1).any(axis=1)]\n",
    "\n",
    "episodes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e632de1",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    " i changed the names of classes, but here they are\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! I can see your degradation data setup. You have:\n",
    "\n",
    "- **4,638 episodes** (time series)\n",
    "- Each episode has **101 time steps** (columns)\n",
    "- These represent crack growth following Paris law with different parameters\n",
    "\n",
    "A few observations:\n",
    "- Your episodes are continuous values (crack lengths in meters)\n",
    "- They're monotonically increasing (cracks grow over time)\n",
    "- You've filtered out invalid/extreme values\n",
    "\n",
    "Now we need to discretize these continuous values into your vocabulary of 100 bins. \n",
    "\n",
    "Should we:\n",
    "1. Look at the range of values in `episodes` first to understand the data better?\n",
    "2. Then create a discretization function that maps continuous values to discrete bins?\n",
    "\n",
    "What would you like to do first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230cc845",
   "metadata": {
    "time_run": "11:37:47a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e93cc5c1f70>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c1fa0>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c20c0>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c21e0>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c2300>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c2420>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c2540>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c2660>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c2780>,\n",
       " <matplotlib.lines.Line2D at 0x7e93cc5c28a0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(episodes[:10].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0687d",
   "metadata": {},
   "source": [
    "## digitize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fa272",
   "metadata": {
    "time_run": "11:37:50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "MPS Available: False\n",
      "Default Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "    print(\"Current CUDA Device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Check if MPS (Apple M-series) is available\n",
    "print(\"MPS Available:\", torch.backends.mps.is_available())\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS Built:\", torch.backends.mps.is_built())\n",
    "\n",
    "# Check default device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Default Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808b889",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "ok, i can see i dont have gpu or mps, just cpu, but thats fine, lets get to work \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! CPU is fine for getting started, especially with your dataset size.\n",
    "\n",
    "Looking at your plot, I can see the crack growth curves are monotonically increasing from around 0.0045 to 0.007 meters over 100 time steps. Nice smooth degradation patterns!\n",
    "\n",
    "Now let's create the discretization. We need to:\n",
    "1. Find the min and max values across all episodes\n",
    "2. Create 100 bins that span this range\n",
    "3. Write a function to map continuous values to discrete bin indices\n",
    "\n",
    "Want to write a small snippet to check the min/max of your data first? Something like:\n",
    "\n",
    "```python\n",
    "print(f\"Min: {episodes.min()}\")\n",
    "print(f\"Max: {episodes.max()}\")\n",
    "```\n",
    "\n",
    "This will help us set up the bins properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e207a0",
   "metadata": {
    "time_run": "11:37:50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 5.835973769329656e-05\n",
      "Max: 0.03955712079339312\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min: {episodes.min()}\")\n",
    "print(f\"Max: {episodes.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a1f20",
   "metadata": {
    "time_run": "11:37:50a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9052711b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i can try to write a function to discrtize data but i was wondering maybe numpy or pytorch has sth efficient and easy to use here, something you aware of?\n",
    "    \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good thinking! Yes, there are efficient built-in options:\n",
    "\n",
    "**NumPy:** `np.digitize()` - takes your data and bin edges, returns bin indices\n",
    "\n",
    "**PyTorch:** `torch.bucketize()` - similar functionality\n",
    "\n",
    "For your case, `np.digitize()` would work well. You'd need to:\n",
    "1. Create bin edges using `np.linspace(min, max, num_bins+1)`\n",
    "2. Use `np.digitize(episodes, bins)` to get discrete indices\n",
    "\n",
    "Want to try implementing this? Or would you like me to show you a small example of how to set it up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f76388",
   "metadata": {
    "time_run": "11:37:50a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def digitize_np(data, min, max, num_bins):\n",
    "    bins = np.linspace(min, max, num_bins+1)\n",
    "    return np.digitize(data, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6d9f4",
   "metadata": {
    "time_run": "11:37:50a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e938830b6e0>,\n",
       " <matplotlib.lines.Line2D at 0x7e938830b920>,\n",
       " <matplotlib.lines.Line2D at 0x7e938830bb90>,\n",
       " <matplotlib.lines.Line2D at 0x7e938830bc20>,\n",
       " <matplotlib.lines.Line2D at 0x7e938830be90>,\n",
       " <matplotlib.lines.Line2D at 0x7e938830bfb0>,\n",
       " <matplotlib.lines.Line2D at 0x7e9388308ec0>,\n",
       " <matplotlib.lines.Line2D at 0x7e938830bbc0>,\n",
       " <matplotlib.lines.Line2D at 0x7e938830ba40>,\n",
       " <matplotlib.lines.Line2D at 0x7e938830b6b0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digitized_episodes = digitize_np(episodes, 0, 0.05, 300)\n",
    "plt.plot(digitized_episodes[:10].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b0b0a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "are we good?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking good! Your discretization is working. I can see the stepped pattern in the plot, which shows the continuous values have been mapped to discrete bins.\n",
    "\n",
    "A couple of observations:\n",
    "- You're using 300 bins instead of the 100 we discussed earlier - is that intentional?\n",
    "- The range [0, 0.05] covers your data well (min was ~0, max was ~0.05)\n",
    "\n",
    "The discretized values should now be integers from 0 to 300 (or 0 to 100 if you switch to 100 bins).\n",
    "\n",
    "Should we stick with 300 bins, or change to 100 as originally planned? Then we can move on to creating the PyTorch dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfb065",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes, that was intentional, 100 bins kills some of the slow trends\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Makes sense! With 100 bins the discretization might be too coarse and you'd lose important gradual changes in the degradation. 300 bins gives you finer granularity to capture those slow trends.\n",
    "\n",
    "So your vocabulary size is now 300 instead of 100. Should we update the other hyperparameters, or keep:\n",
    "- vocab_size = 300\n",
    "- context_window = 40\n",
    "- embedding_dim = 128\n",
    "\n",
    "Ready to move on to creating the PyTorch dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd469021",
   "metadata": {},
   "source": [
    "## data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1f67f",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data, vocab_size=300, context_window=40, bs=32):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.context_window = context_window\n",
    "        self.bs = bs\n",
    "        self.data = data\n",
    "\n",
    "    def batch(self):\n",
    "        N,L = self.data.shape\n",
    "        # get a random index of batch size\n",
    "        col_inx = np.random.randint(low=0, high=L-self.context_window, size=self.bs)\n",
    "        row_inx = np.random.randint(low=0, high=N, size=self.bs)\n",
    "        x_b = np.array([self.data[row, col:col+self.context_window] for row,col in zip(row_inx,col_inx)])\n",
    "        y_b = np.array([self.data[row, col+self.context_window] for row,col in zip(row_inx,col_inx)])\n",
    "\n",
    "        return x_b, y_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df64e2b8",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(digitized_episodes)\n",
    "\n",
    "x,y = dataset.batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010bea4",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 40), (32,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e8bf4",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e27da638",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i created a dataset, numpy version, but i doubt it is just rukky style, what do you think, tell me about datasets, i think they should be generator like\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're right to think about this! Your current approach works but isn't following PyTorch conventions. Let me explain the typical patterns:\n",
    "\n",
    "**PyTorch Dataset conventions:**\n",
    "- Inherit from `torch.utils.data.Dataset`\n",
    "- Implement `__len__()` - returns total number of samples\n",
    "- Implement `__getitem__(idx)` - returns one sample at index idx\n",
    "- Use `DataLoader` to handle batching, shuffling, etc.\n",
    "\n",
    "**Your current approach:**\n",
    "- Generates random batches on the fly (more like a generator)\n",
    "- Works, but you lose PyTorch's nice features (multi-processing, automatic batching, etc.)\n",
    "\n",
    "**Question:** For your time series, what counts as one \"sample\"? Is it:\n",
    "- One window of 40 values + 1 target from a single episode?\n",
    "- How many total samples do you have across all episodes?\n",
    "\n",
    "Once we clarify this, we can design the dataset properly. What do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ae5d5",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes, sample is One window of 40 values + 1 target from a single episode, that means 60 samples from each episode\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! So with 4,624 episodes and 60 samples per episode, you have approximately **277,440 total samples**.\n",
    "\n",
    "Now you can create a proper PyTorch dataset:\n",
    "\n",
    "```python\n",
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, context_window=40):\n",
    "        self.data = data\n",
    "        self.context_window = context_window\n",
    "        self.n_episodes, self.episode_length = data.shape\n",
    "        self.samples_per_episode = self.episode_length - context_window\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_episodes * self.samples_per_episode\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert flat index to (episode, position)\n",
    "        episode_idx = idx // self.samples_per_episode\n",
    "        pos = idx % self.samples_per_episode\n",
    "        \n",
    "        x = self.data[episode_idx, pos:pos+self.context_window]\n",
    "        y = self.data[episode_idx, pos+self.context_window]\n",
    "        \n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "```\n",
    "\n",
    "Want to try implementing this and testing it with a DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ba692",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, context_window=40):\n",
    "        self.data = data\n",
    "        self.context_window = context_window\n",
    "        self.n_episodes, self.episode_length = data.shape\n",
    "        self.samples_per_episode = self.episode_length - context_window\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_episodes * self.samples_per_episode\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert flat index to (episode, position)\n",
    "        episode_idx = idx // self.samples_per_episode\n",
    "        pos = idx % self.samples_per_episode\n",
    "        \n",
    "        x = self.data[episode_idx, pos:pos+self.context_window]\n",
    "        y = self.data[episode_idx, pos+self.context_window]\n",
    "        \n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08dc2e",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "dataset = TimeSeriesDataset(digitized_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4dda1a",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32,\n",
       "         32, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 35, 35,\n",
       "         35, 35, 35, 35]),\n",
       " tensor(35))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574464c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i liked it, so should we test it with a data loader?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes! Let's test it with a DataLoader. Try creating one like this:\n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "```\n",
    "\n",
    "Then grab a batch to see if it works:\n",
    "\n",
    "```python\n",
    "x_batch, y_batch = next(iter(dataloader))\n",
    "print(x_batch.shape, y_batch.shape)\n",
    "```\n",
    "\n",
    "Give it a try and let me know what shapes you get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42779bab",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4dfc8",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(dataloader))\n",
    "print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c6e33",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i got 32,40 and 32 which makes sense, should we have a train test split here?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, definitely! You'll want to evaluate on unseen episodes to see if your model generalizes.\n",
    "\n",
    "You can split your episodes before creating datasets:\n",
    "\n",
    "```python\n",
    "# Split episodes into train/test (e.g., 80/20)\n",
    "n_train = int(0.8 * len(digitized_episodes))\n",
    "train_episodes = digitized_episodes[:n_train]\n",
    "test_episodes = digitized_episodes[n_train:]\n",
    "```\n",
    "\n",
    "Then create separate datasets and dataloaders for each.\n",
    "\n",
    "Want to try implementing this split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403363f0",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "# Split episodes into train/test (e.g., 80/20)\n",
    "n_train = int(0.8 * len(digitized_episodes))\n",
    "train_episodes = digitized_episodes[:n_train]\n",
    "test_episodes = digitized_episodes[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc8cdf2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "is this a common practice to have two dataloaders for train test??\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, absolutely! Having separate train and test DataLoaders is standard practice in PyTorch. It's very common to see:\n",
    "\n",
    "```python\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "```\n",
    "\n",
    "Notice:\n",
    "- **Train loader:** `shuffle=True` - randomizes order each epoch\n",
    "- **Test loader:** `shuffle=False` - keeps consistent order for evaluation\n",
    "\n",
    "This way during training you iterate over `train_loader`, and during evaluation you iterate over `test_loader`. Clean separation!\n",
    "\n",
    "Want to set up your train/test split and create both loaders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b28297",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "train_dataset = TimeSeriesDataset(train_episodes)\n",
    "test_dataset = TimeSeriesDataset(test_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e2a9a",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3652a3",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 5,  5,  5,  ...,  8,  8,  8],\n",
       "         [ 5,  5,  5,  ...,  8,  8,  8],\n",
       "         [ 5,  5,  5,  ...,  8,  8,  8],\n",
       "         ...,\n",
       "         [ 7,  7,  7,  ..., 12, 12, 12],\n",
       "         [ 7,  7,  7,  ..., 12, 12, 13],\n",
       "         [ 7,  7,  8,  ..., 12, 13, 13]]),\n",
       " tensor([ 8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10,\n",
       "         11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a597846",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataLoader__initialized',\n",
       " '_DataLoader__multiprocessing_context',\n",
       " '_IterableDataset_len_called',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_collation',\n",
       " '_dataset_kind',\n",
       " '_get_iterator',\n",
       " '_index_sampler',\n",
       " '_iterator',\n",
       " 'batch_sampler',\n",
       " 'batch_size',\n",
       " 'check_worker_number_rationality',\n",
       " 'collate_fn',\n",
       " 'dataset',\n",
       " 'drop_last',\n",
       " 'generator',\n",
       " 'in_order',\n",
       " 'multiprocessing_context',\n",
       " 'num_workers',\n",
       " 'persistent_workers',\n",
       " 'pin_memory',\n",
       " 'pin_memory_device',\n",
       " 'prefetch_factor',\n",
       " 'sampler',\n",
       " 'timeout',\n",
       " 'worker_init_fn']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f62557",
   "metadata": {},
   "source": [
    "## embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a0b98",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "makes sense?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your data pipeline is now set up properly:\n",
    "- Train dataset with shuffling for randomization during training\n",
    "- Test dataset without shuffling for consistent evaluation\n",
    "- Both using the same context window and vocabulary\n",
    "\n",
    "Now you're ready to implement the transformer model! \n",
    "\n",
    "Should we start building the transformer architecture based on everything we discussed earlier (embeddings, multi-head attention, feed-forward, etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5af271",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes, lets do it\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's build the transformer step by step.\n",
    "\n",
    "We discussed these components earlier:\n",
    "1. **Embedding layer** (token + positional)\n",
    "2. **Multi-head attention**\n",
    "3. **Feed-forward network (MLP)**\n",
    "4. **Layer normalization and residual connections**\n",
    "5. **Output projection** (to vocabulary)\n",
    "\n",
    "Let's start with the embedding layer. Based on our discussion, you need:\n",
    "- Token embeddings: `(vocab_size=300, embedding_dim=128)`\n",
    "- Positional embeddings: `(context_window=40, embedding_dim=128)`\n",
    "- Add them together\n",
    "\n",
    "Want to try writing the embedding part, or would you like me to show you how to structure it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1f1e2",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "# token embedding\n",
    "\n",
    "class Embedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size=300, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embed = torch.nn.Embedding(vocab_size,embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bef2be",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 128])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = Embedding()\n",
    "x=torch.tensor([[0, 4, 299], [1, 5, 290]])\n",
    "ex=embed(x[None,...])\n",
    "ex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b396d0",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "how is this, i guess i dont need to buils a class, just call nn.Embedding??\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're right! You don't need a separate class just for token embeddings. You can use `nn.Embedding` directly.\n",
    "\n",
    "However, remember from our discussion: you need to add **positional embeddings** too! So you might want a class that does:\n",
    "- Token embedding\n",
    "- Positional embedding  \n",
    "- Adds them together\n",
    "\n",
    "Something like:\n",
    "\n",
    "```python\n",
    "class TokenPositionEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, context_window, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_embed = nn.Embedding(context_window, embedding_dim)\n",
    "```\n",
    "\n",
    "Want to add the positional part to your embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7ff08",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class TokenPositionEmbedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, context_window, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.token_embed = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_embed = torch.nn.Embedding(context_window, embedding_dim)\n",
    "    def forward(self, x):\n",
    "        # embedding will be added as the last dimention\n",
    "        tex = self.token_embed(x)\n",
    "        pex = self.pos_embed(torch.arange(x.size(-1), device=x.device).unsqueeze(0))\n",
    "        return tex+pex\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2802c",
   "metadata": {
    "time_run": "11:37:51a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   4, 299],\n",
       "        [  1,   5, 290]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63dc6ad",
   "metadata": {
    "heading_collapsed": true,
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 128])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenPositionEmbedding(300, 40, 128)(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc6d9d",
   "metadata": {
    "hidden": 1,
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(x.size(-1), device=x.device).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb4ee8",
   "metadata": {
    "hidden": 1,
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734baf9",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "check it out!\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Nice work! Your `TokenPositionEmbedding` looks good. A couple of observations:\n",
    "\n",
    "**What's working:**\n",
    "- You're creating both token and position embeddings\n",
    "- Adding them together\n",
    "- Using `torch.arange` to generate position indices\n",
    "\n",
    "**Small note on the positional embedding:**\n",
    "Your `pex` will broadcast correctly, but you might want to expand it to match the batch dimension explicitly for clarity. Right now it's shape `(1, seq_len, embed_dim)` and broadcasts to `(batch, seq_len, embed_dim)`.\n",
    "\n",
    "**Testing:**\n",
    "When you test with `x` of shape `(2, 3)` (batch=2, seq_len=3), you should get output `(2, 3, 128)`. \n",
    "\n",
    "Try testing with your actual batch from the dataloader to make sure it works with shape `(32, 40)`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28222a",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 40, 128])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "x = next(iter(train_loader))[0]\r\n",
    "TokenPositionEmbedding(300, 40, 128)(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd9a98",
   "metadata": {},
   "source": [
    "## Attention block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea5513",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "am i doing it right?\r\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! You got `(32, 40, 128)` which is exactly right:\n",
    "- 32 = batch size\n",
    "- 40 = context window (sequence length)\n",
    "- 128 = embedding dimension\n",
    "\n",
    "Your embedding layer is working correctly! \n",
    "\n",
    "Now, ready to build the multi-head attention layer? That's the next component we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c36675",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes, but before that am i calling dataloader in right way? i mean its returning a list of like [x, y], i would prefer a tuple! or is it fine?\r\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good observation! Actually, it's returning a **list** `[x, y]` instead of a tuple `(x, y)`. Both work fine for unpacking with `x, y = next(iter(train_loader))`, but if you prefer tuples, you can customize the collate function.\n",
    "\n",
    "However, the default behavior is fine and very common in PyTorch. Most people just unpack it as you're doing. It's not worth worrying about unless you have a specific reason to need tuples.\n",
    "\n",
    "Your current approach is perfectly fine! Ready to move on to multi-head attention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19fe54c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes thanks, let move to multihead attention\r\n",
    " \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's build multi-head attention.\n",
    "\n",
    "From our discussion, remember the key steps:\n",
    "1. Create Q, K, V projections from input\n",
    "2. Split into multiple heads (let's say 8 heads, so 128/8 = 16 dims per head)\n",
    "3. Compute attention scores: Q @ K^T\n",
    "4. Scale by √(head_dim)\n",
    "5. Apply softmax\n",
    "6. Multiply by V\n",
    "7. Concatenate heads and project\n",
    "\n",
    "Here's the structure to start with:\n",
    "\n",
    "```python\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        # Q, K, V projections\n",
    "        # Output projection\n",
    "```\n",
    "\n",
    "Want to try filling in the `__init__` with the weight matrices? What shapes do you think they should be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf1ea5",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        #remember input is 32,40,128\n",
    "        # Q, K, V projections\n",
    "        self.qproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.kproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.vproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        # Output projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487a6cff",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "makes sense?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, perfect! Your Q, K, V projections are correct:\n",
    "- Each is `(128, 128)` - takes embedding_dim in, outputs embedding_dim\n",
    "- No bias is standard for these projections\n",
    "\n",
    "Now you need to add:\n",
    "1. Store `num_heads` and calculate `head_dim = embedding_dim // num_heads`\n",
    "2. Output projection: another Linear layer `(embedding_dim, embedding_dim)`\n",
    "\n",
    "Want to add those two things?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bce96",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        #remember input is 32,40,128\n",
    "        # Q, K, V projections\n",
    "        self.qproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.kproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.vproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        # Output projection\n",
    "        head_dim = embedding_dim // num_heads\n",
    "        self.qproject_mh = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.kproject_mh = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.vproject_mh = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d8c50",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "looks good`?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Wait, I think there's some confusion here. You don't need separate projections for multi-head!\n",
    "\n",
    "The Q, K, V projections you already have (`qproject`, `kproject`, `vproject`) are used for **all heads**. You just reshape their output to split into multiple heads.\n",
    "\n",
    "So you should:\n",
    "- Keep your original 3 projections (Q, K, V)\n",
    "- Add just **one** output projection at the end\n",
    "- Remove the `_mh` projections\n",
    "\n",
    "The multi-head part happens by reshaping, not by having separate weight matrices. Does that make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dea8af",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i dont understand\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let me clarify! \n",
    "\n",
    "You have one set of Q, K, V projections that output `(batch, seq_len, 128)`.\n",
    "\n",
    "Then you **reshape** that 128 dimensions into `(num_heads, head_dim)`. For example with 8 heads:\n",
    "- Before reshape: `(32, 40, 128)`\n",
    "- After reshape: `(32, 40, 8, 16)` \n",
    "- Then rearrange to: `(32, 8, 40, 16)` so you have 8 separate heads\n",
    "\n",
    "Each head works on its own 16-dimensional slice. You don't need separate weight matrices - the reshaping creates the heads!\n",
    "\n",
    "Does this make more sense? The same Q/K/V weights are used, but their outputs get split into heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32cfd55",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84abcbe3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i am not sure how to do the reshape, i guess reshape happens in the forward function not here, here we build the layers we need?? \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Exactly right! The reshape happens in the `forward` function, not in `__init__`.\n",
    "\n",
    "In `__init__`, you only need:\n",
    "- The 3 projections (Q, K, V) you already have\n",
    "- One output projection\n",
    "- Store `num_heads` and `head_dim` as attributes\n",
    "\n",
    "So your `__init__` should look like:\n",
    "\n",
    "```python\n",
    "def __init__(self, embedding_dim, num_heads):\n",
    "    super().__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.head_dim = embedding_dim // num_heads\n",
    "    \n",
    "    self.qproject = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "    self.kproject = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "    self.vproject = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "    self.out_project = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "```\n",
    "\n",
    "Then in `forward`, you'll do the reshaping. Does this make sense now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf913d3",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        #remember input is 32,40,128\n",
    "        # Q, K, V projections\n",
    "        self.qproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.kproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.vproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        # Output projection\n",
    "        self.head_dim = embedding_dim // num_heads\n",
    "        self.out_project = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3367da",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "so is this all, the rest including the softmax and multiplications goes into forward?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, exactly! Your `__init__` is complete now.\n",
    "\n",
    "All the computation logic goes in `forward`:\n",
    "- Apply Q, K, V projections\n",
    "- Reshape to split into heads\n",
    "- Compute attention scores (Q @ K^T)\n",
    "- Scale by √head_dim\n",
    "- Apply softmax\n",
    "- Multiply by V\n",
    "- Concatenate heads\n",
    "- Apply output projection\n",
    "\n",
    "Ready to work on the `forward` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b2c8be",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Q, K, V projections\n",
    "        self.qproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.kproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.vproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        # Output projection\n",
    "        self.head_dim = embedding_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.out_project = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        from math import sqrt\n",
    "        #remember input is 32,40,128\n",
    "        q=self.qproject(x)\n",
    "        k=self.kproject(x)\n",
    "        v=self.vproject(x)\n",
    "\n",
    "        # reshape to heads\n",
    "        q = torch.reshape(q, (q.size(0),-1,self.num_heads, self.head_dim)).permute(0,2,1,3) # 32,8,40,16\n",
    "        k = torch.reshape(k, (k.size(0),-1,self.num_heads, self.head_dim)).permute(0,2,1,3) # 32,8,40,16\n",
    "        v = torch.reshape(v, (v.size(0),-1,self.num_heads, self.head_dim)).permute(0,2,1,3) # 32,8,40,16\n",
    "\n",
    "        score = q@k.permute(0,1,3,2) / sqrt(self.head_dim) # 32,8,40,40\n",
    "        soft_score = torch.softmax(score, dim=-1) # 32,8,40,40\n",
    "        scoreV = soft_score@v  # 32,8,40,16\n",
    "        sv = scoreV.permute(0,2,1,3).contiguous().view(scoreV.size(0), scoreV.size(2), -1)        \n",
    "        out = self.out_project(sv)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14515dbd",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "how is it so far\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent work! Your multi-head attention implementation looks really solid. Let me check the key parts:\n",
    "\n",
    "✓ Q, K, V projections  \n",
    "✓ Reshape to `(batch, num_heads, seq_len, head_dim)`  \n",
    "✓ Attention scores: Q @ K^T  \n",
    "✓ Scaling by √head_dim  \n",
    "✓ Softmax on last dimension  \n",
    "✓ Multiply by V  \n",
    "✓ Concatenate heads back (permute + view)  \n",
    "✓ Output projection  \n",
    "\n",
    "This looks correct! Want to test it with your embedded data to make sure the shapes work out?\n",
    "\n",
    "```python\n",
    "x_embedded = TokenPositionEmbedding(300, 40, 128)(x)\n",
    "mha = MultiHeadAttention(128, 8)\n",
    "output = mha(x_embedded)\n",
    "print(output.shape)  # Should be (32, 40, 128)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631535b5",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 128])\n"
     ]
    }
   ],
   "source": [
    "x_embedded = TokenPositionEmbedding(300, 40, 128)(x)\n",
    "mha = MultiHeadAttention(128, 8)\n",
    "output = mha(x_embedded)\n",
    "print(output.shape)  # Should be (32, 40, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7cc564",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "405fd95f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i think it works now but please explain this before goinin gon:\r\n",
    "scoreV.permute(0,2,1,3).contiguous().view(scoreV.size(0), scoreV.size(2), -1)   \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! Let's break down that line step by step:\n",
    "\n",
    "**Starting point:** `scoreV` has shape `(32, 8, 40, 16)` \n",
    "- 32 = batch\n",
    "- 8 = num_heads  \n",
    "- 40 = seq_len\n",
    "- 16 = head_dim\n",
    "\n",
    "**Step 1: `.permute(0,2,1,3)`** → `(32, 40, 8, 16)`\n",
    "- Swaps the heads and sequence dimensions\n",
    "- Now heads and head_dim are next to each other\n",
    "\n",
    "**Step 2: `.contiguous()`**\n",
    "- After permute, memory layout might not be contiguous\n",
    "- This ensures the tensor is stored contiguously in memory (required for view)\n",
    "\n",
    "**Step 3: `.view(scoreV.size(0), scoreV.size(2), -1)`** → `(32, 40, 128)`\n",
    "- Flattens the last two dimensions: `8 * 16 = 128`\n",
    "- This concatenates all heads back together\n",
    "\n",
    "So you're going from separate heads `(32, 8, 40, 16)` back to a single embedding `(32, 40, 128)`.\n",
    "\n",
    "Does this clarify it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3e97d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes\r\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Now you have a working multi-head attention layer.\n",
    "\n",
    "Next components we need:\n",
    "1. Feed-forward network (MLP)\n",
    "2. Layer normalization\n",
    "3. Residual connections\n",
    "\n",
    "Then we can put it all together into a transformer block.\n",
    "\n",
    "Which one would you like to tackle next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c96bf4e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "whats the order here? i think we should do original residual connection, then layer norm, then linear, then relu, then linear, then residual, then layer norm, \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good thinking! You're close, but let me clarify the standard order for a transformer block:\n",
    "\n",
    "**1. Multi-head attention block:**\n",
    "- Input → Multi-head attention → Add input (residual) → Layer norm\n",
    "\n",
    "**2. Feed-forward block:**\n",
    "- Output from above → Linear → ReLU (or GELU) → Linear → Add input to this block (residual) → Layer norm\n",
    "\n",
    "So there are **two separate residual connections** - one around attention, one around the feed-forward network. Each has its own layer norm after the residual add.\n",
    "\n",
    "Does this match what you were thinking, or should I clarify further?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e494c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "that was my thinking, now i can go ahead and add res and norm to mha, to complete it, makes sense?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, perfect! Go ahead and add the residual connection and layer normalization to your `MultiHeadAttention` class.\n",
    "\n",
    "You'll need to:\n",
    "1. Add `nn.LayerNorm(embedding_dim)` in `__init__`\n",
    "2. In `forward`, add the input to the output and then normalize\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96dd6b",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Q, K, V projections\n",
    "        self.qproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.kproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.vproject = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        # Output projection\n",
    "        self.head_dim = embedding_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.out_project = torch.nn.Linear(embedding_dim,embedding_dim,bias=False)\n",
    "        self.layernorm = torch.nn.LayerNorm(embedding_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        from math import sqrt\n",
    "        #remember input is 32,40,128\n",
    "        q=self.qproject(x)\n",
    "        k=self.kproject(x)\n",
    "        v=self.vproject(x)\n",
    "\n",
    "        # reshape to heads\n",
    "        q = torch.reshape(q, (q.size(0),-1,self.num_heads, self.head_dim)).permute(0,2,1,3) # 32,8,40,16\n",
    "        k = torch.reshape(k, (k.size(0),-1,self.num_heads, self.head_dim)).permute(0,2,1,3) # 32,8,40,16\n",
    "        v = torch.reshape(v, (v.size(0),-1,self.num_heads, self.head_dim)).permute(0,2,1,3) # 32,8,40,16\n",
    "\n",
    "        score = q@k.permute(0,1,3,2) / sqrt(self.head_dim) # 32,8,40,40\n",
    "        soft_score = torch.softmax(score, dim=-1) # 32,8,40,40\n",
    "        scoreV = soft_score@v  # 32,8,40,16\n",
    "        sv = scoreV.permute(0,2,1,3).contiguous().view(scoreV.size(0), scoreV.size(2), -1)        \n",
    "        mha_out = self.out_project(sv) #32,40,128\n",
    "        mha_out_plus_input = mha_out + x #32,40,128\n",
    "        out = self.layernorm(mha_out_plus_input) #32,40,128\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a51c52c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "correct?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your multi-head attention with residual connection and layer normalization is correct:\n",
    "\n",
    "✓ Add input `x` to the attention output (residual)  \n",
    "✓ Apply layer normalization  \n",
    "✓ Return normalized output with shape `(32, 40, 128)`\n",
    "\n",
    "Now you're ready to build the feed-forward network (MLP) block. Want to start on that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46082d",
   "metadata": {},
   "source": [
    "## feed forward block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e21def",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes let go\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! The feed-forward network (MLP) is simpler than attention.\n",
    "\n",
    "From our discussion, remember it has:\n",
    "- First linear layer: `(embedding_dim, d_ff)` where `d_ff` is typically 4× larger (so 128 → 512)\n",
    "- Activation function: GELU or ReLU\n",
    "- Second linear layer: `(d_ff, embedding_dim)` to project back (512 → 128)\n",
    "- Residual connection + layer norm\n",
    "\n",
    "Want to try implementing the `FeedForward` class? Start with `__init__` and the layers you'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95db765",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.first_proj = torch.nn.Linear(embedding_dim, int(4*embedding_dim))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.second_proj = torch.nn.Linear(int(4*embedding_dim), embedding_dim)\n",
    "        self.layernorm = torch.nn.LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is shape 32, 40, 128\n",
    "        x_proj1 = self.first_proj(x) # 32, 40, 4*128\n",
    "        x_proj1_relu = self.relu(x_proj1)# 32, 40, 4*128\n",
    "        x_proj2 = self.second_proj(x_proj1_relu)# 32, 40, 128\n",
    "        x_proj2_plus_input = x_proj2 + x # 32, 40, 4*128\n",
    "        out = self.layernorm(x_proj2_plus_input) # 32, 40, 4*128\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e069932",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "looks good?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looks great! Your feed-forward network is correct:\n",
    "\n",
    "✓ First projection: 128 → 512  \n",
    "✓ ReLU activation  \n",
    "✓ Second projection: 512 → 128  \n",
    "✓ Residual connection (add input)  \n",
    "✓ Layer normalization  \n",
    "\n",
    "Perfect! Now you have both major components. Ready to combine them into a complete **TransformerBlock**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c2e09",
   "metadata": {},
   "source": [
    "## Transformer block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1d936",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets go\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! A `TransformerBlock` combines both components:\n",
    "\n",
    "1. Multi-head attention (with residual + norm)\n",
    "2. Feed-forward network (with residual + norm)\n",
    "\n",
    "Try creating the class:\n",
    "\n",
    "```python\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        # Add your MultiHeadAttention and FeedForward here\n",
    "```\n",
    "\n",
    "The `forward` method should just pass the input through attention, then through feed-forward. Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eee804",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        # Add your MultiHeadAttention and FeedForward here\n",
    "        self.mha = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.ff = FeedForward(embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mha_out = self.mha(x)\n",
    "        out = self.ff(mha_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0977c6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "good?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Your `TransformerBlock` is clean and correct:\n",
    "\n",
    "✓ Multi-head attention first  \n",
    "✓ Feed-forward second  \n",
    "✓ Each has its own residual + norm built in  \n",
    "\n",
    "Now you can stack multiple transformer blocks and add the final output layer to create your complete model. Ready to build the full model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e9832",
   "metadata": {},
   "source": [
    "## Degradation transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135864a2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "never been this ready!\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Love the enthusiasm! \n",
    "\n",
    "For the full model, you'll need:\n",
    "1. **Token + Position Embedding** (you have this)\n",
    "2. **Stack of N TransformerBlocks** (maybe start with 4 blocks?)\n",
    "3. **Final output layer** - remember our discussion about taking the last position and projecting to vocab_size?\n",
    "\n",
    "Want to start building the main model class? What should we call it - `TimeSeriesTransformer` or something else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ca636",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class DegradationTransformer(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, context_window, embedding_dim, num_heads, num_blocks):\n",
    "        super().__init__()\n",
    "        self.tpembed = TokenPositionEmbedding(vocab_size, context_window, embedding_dim)\n",
    "        self.tbls_list = torch.nn.ModuleList([TransformerBlock(embedding_dim, num_heads) for _ in range(num_blocks)])\n",
    "        self.lm_head = torch.nn.Linear(embedding_dim, vocab_size, bias=False)\n",
    "        self.lm_head.weight = self.tpembed.token_embed.weight  # Weight tying\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input is 32*40\n",
    "        x = self.tpembed(x) # 32*40*128\n",
    "        for block in self.tbls_list:\n",
    "            x = block(x) # 32*40*128\n",
    "        last_x = x[:,-1, :] # 32*128\n",
    "        vocab_x = self.lm_head(last_x) # 32*300\n",
    "        return vocab_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd930b3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "are we good, you sure that we have self.tpembed.token_embed?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let me check your `TokenPositionEmbedding` class - yes, you do have `self.token_embed` in there!\n",
    "\n",
    "Your `DegradationTransformer` looks excellent:\n",
    "\n",
    "✓ Token + position embeddings  \n",
    "✓ Stack of transformer blocks using `ModuleList`  \n",
    "✓ Extract last position `[:, -1, :]`  \n",
    "✓ Project to vocabulary  \n",
    "✓ Weight tying between embeddings and output  \n",
    "\n",
    "This should work! Want to test it with a batch to make sure all the shapes work out?\n",
    "\n",
    "```python\n",
    "model = DegradationTransformer(vocab_size=300, context_window=40, \n",
    "                               embedding_dim=128, num_heads=8, num_blocks=4)\n",
    "output = model(x)\n",
    "print(output.shape)  # Should be (32, 300)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f014e",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 40])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a6a3b",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 300])\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "model = DegradationTransformer(vocab_size=300, context_window=40, \n",
    "                               embedding_dim=64, num_heads=4, num_blocks=3)\n",
    "output = model(x)\n",
    "print(output.shape)  # Should be (32, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d3df2",
   "metadata": {},
   "source": [
    "### weight tying tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad17e98",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [],
   "source": [
    "tpembedding = TokenPositionEmbedding(300, 40, 128)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c690c9b",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.children of TokenPositionEmbedding(\n",
       "  (token_embed): Embedding(300, 128)\n",
       "  (pos_embed): Embedding(40, 128)\n",
       ")>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpembedding.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269f213",
   "metadata": {
    "time_run": "11:37:52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 128])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpembedding.token_embed.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6ed29",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1ce35",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i think we look good, now we have output with shape 32,300, meaning we have predicted embeddings for a batch, whats next? \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! You have logits of shape `(32, 300)` - unnormalized scores for each token in the vocabulary.\n",
    "\n",
    "Next steps:\n",
    "1. **Compute loss** - compare these logits to your ground truth targets using cross-entropy\n",
    "2. **Set up optimizer** - like Adam\n",
    "3. **Create training loop** - iterate through batches, compute loss, backprop, update weights\n",
    "\n",
    "Want to start with the loss calculation? You have your targets `y` from the dataloader with shape `(32,)`. How would you compute the loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e7a12a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "yes, unnormalized! dont we need to make these to probabilities?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! For **computing loss**, you don't need to convert to probabilities first. \n",
    "\n",
    "PyTorch's `nn.CrossEntropyLoss` takes the raw logits directly and handles the softmax internally (it's more numerically stable that way).\n",
    "\n",
    "So you can do:\n",
    "```python\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(output, y)  # output is (32, 300), y is (32,)\n",
    "```\n",
    "\n",
    "However, for **inference/prediction** (choosing which token to predict), you would apply softmax or just take argmax of the logits.\n",
    "\n",
    "Does this distinction make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cceebe",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "ok, clarified! lets move on\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Now let's set up the training components.\n",
    "\n",
    "You need:\n",
    "1. Loss function: `nn.CrossEntropyLoss()`\n",
    "2. Optimizer: like `torch.optim.Adam(model.parameters(), lr=...)`\n",
    "3. Training loop\n",
    "\n",
    "Want to start by creating the loss function and optimizer? What learning rate do you think would be good to start with?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9057d",
   "metadata": {},
   "source": [
    "## preliminery training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bbc65",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "we can start with a chossen learning rate but maybe a scheduler we should have next, not sure, what do you think?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good thinking! Schedulers can definitely help, but let's keep it simple to start:\n",
    "\n",
    "**Initial approach:**\n",
    "- Start with a fixed learning rate (like 3e-4 or 1e-3)\n",
    "- Get training working first\n",
    "- Monitor the loss curves\n",
    "\n",
    "**Add scheduler later if needed:**\n",
    "- If loss plateaus, try learning rate decay\n",
    "- Or use a warmup + cosine schedule (common for transformers)\n",
    "\n",
    "My suggestion: Start without a scheduler, see how training goes, then add one if you need it. Sound good?\n",
    "\n",
    "What learning rate do you want to try first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5b770",
   "metadata": {
    "time_run": "11:37:56a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec6810",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "how is it\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! `lr=0.001` is a reasonable starting point for Adam.\n",
    "\n",
    "Now you need:\n",
    "- Loss function: `nn.CrossEntropyLoss()`\n",
    "- Training loop structure\n",
    "\n",
    "Want to create the loss function, then start building the training loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d11024",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets build the loop, we can add this loos on the fly\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's build the training loop step by step.\n",
    "\n",
    "The basic structure is:\n",
    "```python\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        # Compute loss\n",
    "        # Backward pass\n",
    "        # Update weights\n",
    "```\n",
    "\n",
    "Want to start filling this in? Try writing the forward pass and loss computation part first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd213a0",
   "metadata": {
    "time_run": "11:37:56a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a22e7",
   "metadata": {
    "time_run": "11:37:56a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dbabfc8",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "check it out\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Wow, excellent work! Your training loop is running and the model is learning!\n",
    "\n",
    "Looking at your results:\n",
    "- **Training loss** dropped from ~0.66 to much lower values (0.01-0.4 range)\n",
    "- **Test predictions** are remarkably close! Many are exactly correct or off by just 1 bin\n",
    "- The model is learning the monotonic degradation pattern\n",
    "\n",
    "A few observations:\n",
    "1. The test predictions show the model understands the sequential nature (predicting 14→14→15→15→16...)\n",
    "2. Most predictions are within 1 bin of the true value - that's really good for a first epoch!\n",
    "\n",
    "What would you like to do next?\n",
    "- Train for more epochs to see if it improves further?\n",
    "- Add some tracking/logging (average loss per epoch)?\n",
    "- Try inference on a full sequence to see multi-step predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207853e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "losses are comming from y vectors, i printed them out, what do you think\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at your test predictions, they're impressively accurate! Most predictions are either exact or off by just 1 bin (like predicting 14 when true is 15, or 19 when true is 18).\n",
    "\n",
    "This suggests your model is learning the degradation patterns really well after just one epoch!\n",
    "\n",
    "The training losses you printed show the model improving as it goes through batches (starting around 0.66 and dropping).\n",
    "\n",
    "What would you like to explore next? More training epochs, or try generating a full multi-step prediction sequence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92caf7e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i cant do more batches as this env in solveit does not allow it, it say interupted by keyboard but i didnt interrupt training, the system did\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Ah, I see! The environment has some limitations on long-running computations. That's why it stopped during training.\n",
    "\n",
    "Some options to work around this:\n",
    "1. **Reduce the number of epochs or batches** - train on fewer iterations at a time\n",
    "2. **Train in smaller chunks** - run training for a bit, save the model, then continue later\n",
    "3. **Reduce batch size or model size** - makes each iteration faster\n",
    "4. **Skip to inference** - your model already learned something useful after partial training!\n",
    "\n",
    "Since your model is already showing good predictions, want to try the multi-step autoregressive prediction we discussed? Generate a full degradation sequence starting from a few initial values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da80260",
   "metadata": {},
   "source": [
    "## reflections after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4730212",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i think test batch is ok, we dont shuffle, and the process of degradation changes its main param every 100 samples, so 100 consequitive samples are very similar as they come from the same deg process, they start with different starting point which does not make a big difference, at this point i know and i knew it before that i should do lots of work for the data, augmentation, including lots of other degradation model, i ahve plan to make a huge dataset its episodes are diverse andrepresentative of many deg processes, but as of now we know that the model and it structure and traiing works\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect understanding! You're absolutely right:\n",
    "\n",
    "- The test data pattern makes sense given how your degradation processes are structured\n",
    "- The model architecture is working correctly (forward pass, loss computation, backprop)\n",
    "- The training loop is functioning properly\n",
    "- Data diversity is a separate concern you'll address later\n",
    "\n",
    "So you've successfully built a working transformer for time series prediction! The foundation is solid.\n",
    "\n",
    "What would you like to do next? Some options:\n",
    "- Run full training (remove breaks, train for multiple epochs)\n",
    "- Add monitoring/callbacks (save model, track losses over time)\n",
    "- Test autoregressive generation (predict multiple steps ahead)\n",
    "- Work on the data augmentation/diversity\n",
    "\n",
    "What interests you most right now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b04de",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets make a plan with these items, in the same order, \r\n",
    "\r\n",
    "Add monitoring/callbacks (save model, track losses over time)\r\n",
    "Test autoregressive generation (predict multiple steps ahead)\r\n",
    "Work on the data augmentation/diversity\r\n",
    "\r\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great plan! Here's the order we'll work through:\n",
    "\n",
    "**1. Add monitoring/callbacks**\n",
    "   - Track train/test losses over epochs\n",
    "   - Save model checkpoints periodically\n",
    "   - Maybe add a simple progress display\n",
    "\n",
    "**2. Test autoregressive generation**\n",
    "   - Take a sequence of L1 values\n",
    "   - Predict next value\n",
    "   - Add prediction to context\n",
    "   - Repeat for T steps\n",
    "   - Compare predictions to ground truth\n",
    "\n",
    "**3. Work on data augmentation/diversity**\n",
    "   - Add more degradation models\n",
    "   - Vary parameters more\n",
    "   - Create a richer, more diverse dataset\n",
    "\n",
    "Sound good? Ready to start with #1 (monitoring and callbacks)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e9212",
   "metadata": {
    "solveit_ai": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1849e1b0",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "good, before we go forward, i feel the training and inference is so slow, i know here i am running on cpu and it is expected, but lets check how many sample we have in test data, how many batches\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good thinking! Let's check the sizes:\n",
    "\n",
    "```python\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")\n",
    "```\n",
    "\n",
    "Try running this to see how much data you're processing. This will help us understand if the slowness is just from the dataset size or something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a44bb",
   "metadata": {
    "time_run": "11:37:56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 1220\n",
      "Number of test batches: 39\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0316332",
   "metadata": {
    "time_run": "11:37:56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 4636\n",
      "Number of train batches: 145\n"
     ]
    }
   ],
   "source": [
    "print(f\"train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Number of train batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d776262",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "can we see how many parameters the model has?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes! You can check the number of parameters like this:\n",
    "\n",
    "```python\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "```\n",
    "\n",
    "This will count all the parameters in your model. Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2cf4c",
   "metadata": {
    "time_run": "11:37:56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 170,944\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840252e9",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "so what do you think, is this doable by a cpu?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, definitely doable on CPU! \n",
    "\n",
    "**834K parameters** is actually quite small for a transformer. For comparison:\n",
    "- GPT-2 small: 117M parameters\n",
    "- Your model: 0.8M parameters\n",
    "\n",
    "With ~7,000 training batches per epoch, it will be slow on CPU but manageable. Each epoch might take several minutes depending on your CPU.\n",
    "\n",
    "You could:\n",
    "- Train for fewer epochs to start (like 5-10)\n",
    "- Use a smaller batch size if memory is tight\n",
    "- Or just be patient - it should finish!\n",
    "\n",
    "Want to proceed with adding the monitoring/callbacks, then run a full training session?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525fe67c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "one last question: with this number of params, how many training samples is sufficient?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! There's a general rule of thumb:\n",
    "\n",
    "**For supervised learning:** You typically want at least **10-100× more training samples than parameters**.\n",
    "\n",
    "With 834K parameters:\n",
    "- Minimum: ~8M samples (10×)\n",
    "- Better: ~80M samples (100×)\n",
    "\n",
    "You have **227K training samples**, which is less than ideal by this rule. However:\n",
    "\n",
    "- Your task is relatively constrained (monotonic degradation)\n",
    "- Time series have local patterns that help\n",
    "- You might still get reasonable results\n",
    "\n",
    "You'll likely see some overfitting, but it's worth trying! If performance is poor, you could:\n",
    "- Reduce model size (fewer blocks, smaller embedding dim)\n",
    "- Add dropout for regularization\n",
    "- Generate more diverse data\n",
    "\n",
    "Want to proceed with training and see how it performs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d7a8b",
   "metadata": {},
   "source": [
    "## Learner with callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac4433",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "back to our plan, lets make a learner from our loop , with callbacks\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's create a `Learner` class that wraps your training loop and supports callbacks.\n",
    "\n",
    "First, what callbacks do you want to include? Some common ones:\n",
    "- Loss tracking (store train/test losses each epoch)\n",
    "- Model checkpointing (save model every N epochs)\n",
    "- Progress printing (show current epoch/loss)\n",
    "\n",
    "Want to start by defining a simple callback structure, then build the Learner class around it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a5392",
   "metadata": {
    "solveit_ai": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "885846f0",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "great, lets start by defining a simple callback structure, then build the Learner class around it\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Let's start with a simple callback structure.\n",
    "\n",
    "A callback typically has methods that get called at different points during training. The basic ones are:\n",
    "- `before_fit()` - called once before training starts\n",
    "- `after_epoch()` - called after each epoch\n",
    "- `after_fit()` - called once after training ends\n",
    "\n",
    "Here's a simple base class:\n",
    "\n",
    "```python\n",
    "class Callback:\n",
    "    def before_fit(self, learner): pass\n",
    "    def after_epoch(self, learner): pass\n",
    "    def after_fit(self, learner): pass\n",
    "```\n",
    "\n",
    "The `learner` parameter gives callbacks access to the model, losses, current epoch, etc.\n",
    "\n",
    "Does this structure make sense? Want to try implementing this base class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced862fe",
   "metadata": {
    "time_run": "11:37:56a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Callback:\n",
    "    def __init__(self): pass\n",
    "    def before_fit(self, learner): pass\n",
    "    def before_batch(self, learner): pass\n",
    "    def before_epoch(self, learner): pass\n",
    "    def after_batch(self, learner): pass\n",
    "    def after_epoch(self, learner): pass\n",
    "    def after_fit(self, learner): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d479da9",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "makes sense?\r\n",
    "\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! You've added even more granular callback hooks:\n",
    "- `before_epoch()` / `after_epoch()` - for epoch-level operations\n",
    "- `before_batch()` / `after_batch()` - for batch-level operations\n",
    "\n",
    "This gives you flexibility to do things like:\n",
    "- Update progress bars after each batch\n",
    "- Log losses after each epoch\n",
    "- Save checkpoints at specific points\n",
    "\n",
    "Now, ready to build the `Learner` class that uses these callbacks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41adb42f",
   "metadata": {
    "time_run": "11:37:56a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "# export learner.py\n",
    "class Learner():\n",
    "    def __init__(self, model, optim, loss_func, train_loader, test_loader, cbs):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.loss_func = loss_func\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.cbs = cbs\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "\n",
    "    def train_one_batch(self, x_batch, y_batch):\n",
    "        self.optim.zero_grad()\n",
    "        # Forward pass\n",
    "        y_predict = self.model(x_batch)\n",
    "        # Compute loss\n",
    "        loss = self.loss_func(y_predict, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        self.optim.step()\n",
    "        return loss\n",
    "\n",
    "    def test_one_batch(self, x_batch, y_batch):\n",
    "        with torch.no_grad():        \n",
    "            # Forward pass\n",
    "            y_test_predict = self.model(x_batch)\n",
    "            # Compute loss\n",
    "            loss = self.loss_func(y_test_predict, y_batch)\n",
    "            \n",
    "            return loss\n",
    "\n",
    "    def fit(self, num_epochs):\n",
    "        for cb in self.cbs:\n",
    "                cb.before_fit(self)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.epoch = epoch\n",
    "            for cb in self.cbs:\n",
    "                cb.before_epoch(self)\n",
    "            \n",
    "            # train loop\n",
    "            for i, (x_batch, y_batch) in enumerate(self.train_loader):\n",
    "                self.train_idx = i\n",
    "                for cb in self.cbs:\n",
    "                    cb.before_batch(self)\n",
    "                self.last_train_loss = self.train_one_batch(x_batch, y_batch)\n",
    "                self.train_losses.append(self.last_train_loss)\n",
    "                for cb in self.cbs:\n",
    "                    cb.after_batch(self)\n",
    "               \n",
    "            # test loop\n",
    "            for i, (x_batch, y_batch) in enumerate(self.test_loader):\n",
    "                self.test_idx = i\n",
    "                print(\"test_i=  \", i)\n",
    "                self.last_test_loss = self.test_one_batch(x_batch, y_batch)\n",
    "                self.test_losses.append(self.last_test_loss)\n",
    "\n",
    "\n",
    "            for cb in self.cbs:\n",
    "                cb.after_epoch(self)\n",
    "\n",
    "        for cb in self.cbs:\n",
    "                cb.after_fit(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7c61f",
   "metadata": {
    "time_run": "11:37:57a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ProgressCallback(Callback):\n",
    "    \n",
    "    def after_batch(self, learner):\n",
    "        if learner.train_idx%50==0:\n",
    "            print(sum(learner.train_losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba53213",
   "metadata": {
    "time_run": "11:37:57a"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "cbs = [ProgressCallback()]\n",
    "learner = Learner(model, optim, loss_func, train_loader, test_loader, cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69329ab2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "a question here, if i call learner.fit(1) does this change model params in place as it does not return any model\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent question! Yes, it **does change the model parameters in place**.\n",
    "\n",
    "When you pass `model` to the `Learner`, you're passing a reference to the model object, not a copy. So when the learner does:\n",
    "- `self.model(x_batch)` - uses your model\n",
    "- `loss.backward()` - computes gradients for your model's parameters\n",
    "- `self.optim.step()` - updates your model's parameters directly\n",
    "\n",
    "After `learner.fit(1)`, your original `model` object will have updated weights. No need to return anything!\n",
    "\n",
    "This is standard PyTorch behavior - models are mutable objects. Does that make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665ca48",
   "metadata": {
    "time_run": "11:38:21a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.2060, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(278.6082, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(384.2619, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_i=   0\n",
      "test_i=   1\n",
      "test_i=   2\n",
      "test_i=   3\n",
      "test_i=   4\n",
      "test_i=   5\n",
      "test_i=   6\n",
      "test_i=   7\n",
      "test_i=   8\n",
      "test_i=   9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_i=   10\n",
      "test_i=   11\n",
      "test_i=   12\n",
      "test_i=   13\n",
      "test_i=   14\n",
      "test_i=   15\n",
      "test_i=   16\n",
      "test_i=   17\n",
      "test_i=   18\n",
      "test_i=   19\n",
      "test_i=   20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_i=   21\n",
      "test_i=   22\n",
      "test_i=   23\n",
      "test_i=   24\n",
      "test_i=   25\n",
      "test_i=   26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_i=   27\n",
      "test_i=   28\n",
      "test_i=   29\n",
      "test_i=   30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_i=   31\n",
      "test_i=   32\n",
      "test_i=   33\n",
      "test_i=   34\n",
      "test_i=   35\n",
      "test_i=   36\n",
      "test_i=   37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_i=   38\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "learner.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c802d",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "a question about this paltform, there is an option for ech cell which says: \"will be exported\" , how can i use it\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! The \"will be exported\" option lets you mark which cells should be included when you export your notebook to a Python file or module.\n",
    "\n",
    "When you mark cells as \"will be exported\", those cells can be extracted into a standalone `.py` file, which is useful for:\n",
    "- Creating reusable modules from your notebook code\n",
    "- Sharing just the important code without exploration/testing cells\n",
    "- Building a package from notebook prototypes\n",
    "\n",
    "Typically you'd mark cells containing your class definitions (like `Learner`, `Callback`, model classes) but not cells with testing or training runs.\n",
    "\n",
    "Does that answer your question, or would you like to know more about how to actually export them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889f9fb",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "but to which file it will be exported, can u give more details\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! The export functionality in this notebook environment typically works like this:\n",
    "\n",
    "**How it works:**\n",
    "- You mark cells with \"will be exported\"\n",
    "- The system can extract those cells to create a `.py` file\n",
    "- Usually there's a command or button to trigger the export\n",
    "\n",
    "**Where it goes:**\n",
    "- Often to a file you specify (like `model.py` or `learner.py`)\n",
    "- Or it might create a file based on a header comment in your notebook\n",
    "\n",
    "**Typical usage:**\n",
    "You might add a comment like `# export model.py` at the top of cells you want exported, and they'd all go into `model.py`.\n",
    "\n",
    "However, the exact mechanism depends on the specific notebook platform. In this solveit environment, I'm not 100% certain of the exact export command. You might need to check the documentation or try looking for an \"Export\" button in the interface.\n",
    "\n",
    "Do you see any export-related buttons or menu options in your interface?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33450b36",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "have a look\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Excellent work! Your `Learner` class looks really solid:\n",
    "\n",
    "✓ Stores all necessary components (model, optimizer, loss, dataloaders, callbacks)  \n",
    "✓ Separates train and test logic into clean methods  \n",
    "✓ Calls callbacks at all the right points  \n",
    "✓ Tracks losses in lists  \n",
    "✓ Uses `torch.no_grad()` for testing  \n",
    "\n",
    "This is a clean, well-structured implementation!\n",
    "\n",
    "Now, want to create some actual callback implementations? Like a `ProgressCallback` to print losses, or a `ModelCheckpoint` callback to save the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66749fa2",
   "metadata": {},
   "source": [
    "## callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04abe7b4",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "lets start with ProgressCallback\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Let's build a `ProgressCallback` that shows training progress.\n",
    "\n",
    "What information would you like it to display? Some options:\n",
    "- Current epoch number\n",
    "- Average loss per epoch\n",
    "- Progress during batches (like every N batches)\n",
    "- Train vs test loss comparison\n",
    "\n",
    "What would be most useful for you to see during training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e43bc3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "two important things for me:\r\n",
    "train and test loss, preferably on a plot\r\n",
    "model activations at certain places in the network, to monitor if the model learns properly, \r\n",
    "\r\n",
    "what do you think about the second in particular?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great ideas! Let me address both:\n",
    "\n",
    "**1. Train and test loss on a plot:** \n",
    "Definitely useful! A callback that collects losses and plots them after each epoch (or at the end) would be perfect for monitoring convergence.\n",
    "\n",
    "**2. Model activations monitoring:**\n",
    "This is really insightful! You could track things like:\n",
    "- Attention score patterns (are heads learning different patterns?)\n",
    "- Embedding norms (are embeddings staying stable?)\n",
    "- Gradient norms (vanishing/exploding gradients?)\n",
    "- Output distributions before softmax\n",
    "\n",
    "However, this can get complex quickly. For a first version, what specific activations interest you most? The attention weights? The embeddings? Or maybe just checking that gradients are flowing properly?\n",
    "\n",
    "What would give you the most confidence that learning is happening correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4226d5",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "i think output distributions before softmax makes alot of sense for me, i expect such distribution is gaussian around the target!?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Interesting intuition! Actually, the output distribution before softmax (the logits) might not be Gaussian, but you'd expect:\n",
    "\n",
    "**What you'd hope to see:**\n",
    "- The logit for the **correct token** should be significantly **higher** than others\n",
    "- As training progresses, this gap should increase (model becomes more confident)\n",
    "- The distribution might be more \"peaked\" around the target, but not necessarily Gaussian\n",
    "\n",
    "**Why not Gaussian:**\n",
    "- Logits are learned scores, not sampled from a distribution\n",
    "- You want one clear winner (the correct token), not a smooth bell curve\n",
    "\n",
    "**What would be useful to track:**\n",
    "- The logit value at the target position vs. the max logit\n",
    "- How many logits are close to the target (top-5 accuracy)\n",
    "- The entropy of the softmax output (lower = more confident)\n",
    "\n",
    "Want to create a callback that tracks these logit statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4cf4a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "you are right, not exactly gaussian, what i meant is the following; \r\n",
    "\r\n",
    "lets say the target is token 20, i expect a peak at 20 but the chances for 19 and 21 should be high, i dont expect a peak at 5, and another at 250 although the peak at 20 is the highest, make sense? or is it too restrictive for a transformer?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That makes perfect sense! You're expecting **local smoothness** in the predictions - nearby bins should have higher probabilities than far-away bins.\n",
    "\n",
    "This is a very reasonable expectation for your degradation data because:\n",
    "- Adjacent bins represent similar crack lengths\n",
    "- If the true value is bin 20, being off by 1-2 bins is much better than being off by 100 bins\n",
    "- The model should learn this continuity\n",
    "\n",
    "**Is this too restrictive for a transformer?**\n",
    "Not at all! The transformer should naturally learn this from your data since:\n",
    "- Your training sequences show smooth, monotonic changes\n",
    "- The patterns in your data have this local structure\n",
    "\n",
    "**How to check this:**\n",
    "A callback could:\n",
    "- Look at the logits/probabilities around the target\n",
    "- Check if neighboring bins have higher values than distant bins\n",
    "- Plot the probability distribution to visualize the \"peakedness\"\n",
    "\n",
    "Want to create a callback that visualizes this distribution for a few samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c45bc",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "you have perfectly put it! i am impressed by your understanding! yes lets make such callback\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Thank you! Let's create a callback to visualize the logit distribution around the target.\n",
    "\n",
    "Here's the structure:\n",
    "\n",
    "```python\n",
    "class LogitDistributionCallback(Callback):\n",
    "    def __init__(self, sample_freq=1):\n",
    "        self.sample_freq = sample_freq  # How often to plot (every N epochs)\n",
    "    \n",
    "    def after_epoch(self, learner):\n",
    "        if learner.epoch % self.sample_freq == 0:\n",
    "            # Get a test batch\n",
    "            # Get model predictions (logits)\n",
    "            # For a few samples, plot logits around the target\n",
    "```\n",
    "\n",
    "Want to try implementing the logic inside `after_epoch`? You'll need to:\n",
    "1. Get one batch from test_loader\n",
    "2. Get the model's logit output\n",
    "3. Pick a sample and plot the logits around its target\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225b3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedf80c",
   "metadata": {
    "time_run": "12:08:39p"
   },
   "outputs": [],
   "source": [
    "class LogitDistributionCallback(Callback):\n",
    "    def __init__(self, sample_freq=1):\n",
    "        self.sample_freq = sample_freq  # How often to plot (every N epochs)\n",
    "    \n",
    "    def after_epoch(self, learner):\n",
    "        if learner.epoch % self.sample_freq == 0:\n",
    "            # Get a test batch\n",
    "            x_batch, y_batch = next(iter(test_loader))\n",
    "            # Get model predictions (logits)\n",
    "            with torch.no_grad:\n",
    "                y_predict = learner.model(x_batch)\n",
    "            # For a few samples, plot logits around the target\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProgressCallback(Callback):\n",
    "    def before_epoch(self, learner):\n",
    "        print(learner.start_time)\n",
    "    def after_batch(self, learner):\n",
    "        print(learner.last_train_loss, learner.last_test_loss)\n",
    "        print(sum(learner.train_losses), sum(learner.test_losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e3fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
